{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c6a406a7",
      "metadata": {
        "id": "c6a406a7"
      },
      "source": [
        "**The SCG-GELP policy contains the following process:**\n",
        "\n",
        "- Setting parameters\n",
        "- SCG-Transformer model to generate synonymous codon sequences\n",
        "- Biological features and transfer learning (DNABER-2) feature extraction\n",
        "- Prediction of highly soluble expressed gene sequences using GELP models (SVM, LR, MLP, CNN-N-NF)\n",
        "- Screening results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Colab environment settings"
      ],
      "metadata": {
        "id": "Pivj4w93p5eG"
      },
      "id": "Pivj4w93p5eG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note: Change Colab runtime hardware gas pedal to T4 GPU**"
      ],
      "metadata": {
        "id": "xUfvQ2Kvp7cm"
      },
      "id": "xUfvQ2Kvp7cm"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c279bce2",
      "metadata": {
        "id": "c279bce2",
        "outputId": "b00bcedd-009a-4bfd-c417-c387c152e82b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.1.0\n",
            "4.48.3\n"
          ]
        }
      ],
      "source": [
        "import triton\n",
        "print(triton.__version__)\n",
        "\n",
        "import transformers\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e9d25c9a",
      "metadata": {
        "id": "e9d25c9a",
        "outputId": "80e0efea-517e-4d57-9d30-700859e3aa89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: triton 3.1.0\n",
            "Uninstalling triton-3.1.0:\n",
            "  Successfully uninstalled triton-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall triton --yes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ef9b4ef8",
      "metadata": {
        "id": "ef9b4ef8",
        "outputId": "b3dd307c-c1e7-4719-cd7a-74673b5e284f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton==3.0.0\n",
            "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton==3.0.0) (3.17.0)\n",
            "Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires triton==3.1.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\", but you have triton 3.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed triton-3.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "triton"
                ]
              },
              "id": "b1b7ae9918ab4f708a6ac4ec8e06bee5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Restart the session after the installation is complete\n",
        "!pip install triton==3.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3fd03ba2",
      "metadata": {
        "id": "3fd03ba2",
        "outputId": "e1ca583a-59aa-463b-9282-77a1e5feb376",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0.0\n",
            "4.48.3\n"
          ]
        }
      ],
      "source": [
        "import triton\n",
        "print(triton.__version__)\n",
        "\n",
        "import transformers\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b10f28dd",
      "metadata": {
        "id": "b10f28dd",
        "outputId": "d8db7f9c-d193-4828-9f49-4a1dc9872993",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "daa0105b",
      "metadata": {
        "id": "daa0105b",
        "outputId": "d317a033-745b-4c1d-d075-7e947cdfcb48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SCG-GELP'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 31 (delta 0), reused 3 (delta 0), pack-reused 27 (from 1)\u001b[K\n",
            "Receiving objects: 100% (31/31), 569.85 MiB | 16.83 MiB/s, done.\n",
            "Updating files: 100% (24/24), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/yuddecho/SCG-GELP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "81c10f1b",
      "metadata": {
        "id": "81c10f1b",
        "outputId": "593d9426-a974-4eff-fbdd-0e7daa1d329f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DNABERT-2-Finetune-1400'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 43 (delta 3), reused 11 (delta 2), pack-reused 29 (from 1)\u001b[K\n",
            "Receiving objects: 100% (43/43), 414.29 MiB | 17.05 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "Updating files: 100% (28/28), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/yuddecho/DNABERT-2-Finetune-1400.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merge model weight files\n",
        "resource_dir = '/content/SCG-GELP'\n",
        "DNABERT_2_checkpoint = '/content/DNABERT-2-Finetune-1400'\n",
        "\n",
        "model_weight_source_dir = [DNABERT_2_checkpoint, resource_dir, resource_dir]\n",
        "source_num_files = [10, 10, 4]\n",
        "source_big_bin_files = ['pytorch_model.bin', 'nesg-cnn-natural-number-512-512-512-1-16-2-False.pt', 'tf_0.0001_512_8_3_3_512_0.1_1024_6.pt']\n",
        "\n",
        "def merge_pt(model_path, target_file, num_files):\n",
        "    print(model_path, target_file, num_files)\n",
        "\n",
        "    model_file_dir = target_file[:-3]\n",
        "    file_name = model_file_dir\n",
        "    tag = target_file[-3:]\n",
        "\n",
        "    if target_file[-3:] != '.pt':\n",
        "        model_file_dir = 'pytorch_model_files'\n",
        "        file_name = target_file[:-4]\n",
        "        tag = target_file[-4:]\n",
        "\n",
        "    # merge\n",
        "    total_contents = bytes()\n",
        "\n",
        "    for i in range(num_files):\n",
        "        file_path = f'{model_path}/{model_file_dir}/{file_name}_{i}{tag}'\n",
        "\n",
        "        with open(file_path, 'rb') as infile:\n",
        "            total_contents += infile.read()\n",
        "\n",
        "    # write\n",
        "    with open(f'{model_path}/{file_name}{tag}', 'wb') as outfile:\n",
        "        outfile.write(total_contents)\n",
        "\n",
        "    print(f'{model_path}/{file_name}{tag}')\n",
        "\n",
        "for path, file, nums in zip(model_weight_source_dir, source_big_bin_files, source_num_files):\n",
        "    merge_pt(path, file, nums)"
      ],
      "metadata": {
        "id": "LanjKHFdqIkr",
        "outputId": "3f64f3c1-e80c-415f-f459-c7bff1445052",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LanjKHFdqIkr",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DNABERT-2-Finetune-1400 pytorch_model.bin 10\n",
            "/content/DNABERT-2-Finetune-1400/pytorch_model.bin\n",
            "/content/SCG-GELP nesg-cnn-natural-number-512-512-512-1-16-2-False.pt 10\n",
            "/content/SCG-GELP/nesg-cnn-natural-number-512-512-512-1-16-2-False.pt\n",
            "/content/SCG-GELP tf_0.0001_512_8_3_3_512_0.1_1024_6.pt 4\n",
            "/content/SCG-GELP/tf_0.0001_512_8_3_3_512_0.1_1024_6.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e04170d",
      "metadata": {
        "id": "2e04170d"
      },
      "source": [
        "## Setting parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "47b5fc29",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.247598Z",
          "start_time": "2024-06-18T13:46:09.657975Z"
        },
        "id": "47b5fc29"
      },
      "outputs": [],
      "source": [
        "# for SCG\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import collections\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.nn.functional import log_softmax\n",
        "\n",
        "from torch import Tensor\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# for biological features\n",
        "import csv\n",
        "from collections import Counter\n",
        "import itertools\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# for DNABERT-2\n",
        "from torch.utils.data import Dataset\n",
        "import csv\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "1faie6ztCndM",
        "outputId": "151877da-9e41-4750-f0f6-a795bfc7a487",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1faie6ztCndM",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "49f51c2b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.252952Z",
          "start_time": "2024-06-18T13:46:11.248746Z"
        },
        "code_folding": [],
        "id": "49f51c2b"
      },
      "outputs": [],
      "source": [
        "# # Get GitHub project resources\n",
        "# !git clone git@github.com:yuddecho/SCG-MELP.git\n",
        "\n",
        "# resource directory\n",
        "# resource_dir =  './resource'\n",
        "# DNABERT_2_checkpoint = './resource/DNABERT-2-Finetune-1400'\n",
        "resource_dir = '/content/SCG-GELP'\n",
        "DNABERT_2_checkpoint = '/content/DNABERT-2-Finetune-1400'\n",
        "\n",
        "# Args\n",
        "protein_name = 'SSS'\n",
        "protein_seq = 'MRIINVKDYEEMSRKAADLIAAQIILNPKSSLGLAHGKSPIGFYERLVELNRNGVIDFSHVTTINLDEYYGLDPTHDQSYRYFMNKHLFSRVNINMANTHLPDGKAKDIDAECIRYDDLIESVGGIDLQLLGIGHNGHIFFNEPSDEFIPGTHCVSLSQSTINANSLMYFSRDEVQRKAITMGIKAIMQARYVQLIASGEDQIEILKKALFGPITPQVPASILQLHKDLTVITPLDI*'\n",
        "dna_wt = 'ATGCGTATCATTAACGTGAAAGACTACGAGGAAATGagcCGTAAGGCGGCGGATCTGATTGCGGCGCAGATCATTCTGAACCCGAAAAGCAGTCTGGGTCTGGCGCatGGCaaaAGCCCGATTGGTTTTTATGAGCGTCTGGTTGAACTGAACCGTAACGGCGTGATCGACTTCAGCCACGTTACCACCATTAACCTGGATGAGTACTATGGTCTGGACCCGACCCACGATCAGAGCTACCGTTATTTCATGAACAAGCACCTGTTTAGCCGTGTGAACATCAACATGGCGAACACCCACCTGCCGGATGGCaaGGCGAAAGACATTGATGCGGAGTGCATTCGTTACGACGATCTGATCGAAAGCGTTGGTGGCATTGACCTGCAACTGCTGGGTATCGGCCACAACGGTCACATTtttTTCAACGAGCCGAGCGATGAATTTATCCCGGGTACCCACTGCGTTAGCCTGAGCCAAAGCACCATTAACGCGAACAGCCTGATGTATTTTAGCCGTGACGAAGTGcaaCGTAAGGCGATCACCATGGGCATCAAAGCGATTATGCAAGCGCGTTATGTTCAGCTGATCGCGAGCGGCGAGGATCAAATTGAAATTCTGAAGAAAGCGCTGTTTGGTCCGATCACCCCGCAGGTGCCGGCGAGCATTCTGCAACTGCACAAGGACCTGACCGTTATCACCCCGCTGGATATTTGA'\n",
        "dna_gs = 'ATGCGTATCATTAACGTGAAAGACTACGAGGAAATGAGCCGTAAGGCGGCGGATCTGATTGCGGCGCAGATCATTCTGAACCCGAAAAGCGTGCTGGGTCTGGCGACCGGCAGCAGCCCGATTGGTACCTATGAGCGTCTGGTTGAACTGAACCGTAACGGCGTGATCGACTTCAGCCACGTTACCACCATTAACCTGGATGAGTACTATGGTCTGGACCCGACCCACGATCAGAGCTACCGTTATTTCATGAACAAGCACCTGTTTAGCCGTGTGAACATCAACATGGCGAACACCCACCTGCCGGATGGCAAGGCGAAAGACATTGATGCGGAGTGCCGTCGTTACGACGATCTGATCGAAAGCGTTGGTGGCATTGACCTGCAACTGCTGGGTATCGGCCACAACGGTCACATTGGCTTCAACGAGCCGAGCGATGAATTTATCCCGGGTACCCACTGCGTTAGCCTGAGCGAGAGCACCATTAACGCGAACAGCCGTTTCTTTAAAAGCCGTGACGAAGTGCCGCGTAAGGCGATCACCATGGGCATCAAAGCGATTATGCAAGCGCGTAAGGTTCTGCTGATCGCGAGCGGCGAGGATAAGAAAGAAATTCTGAAGAAAGCGCTGTTTGGTCCGATCACCCCGCAGGTGCCGGCGAGCATTCTGCAACTGCACAAGGACCTGACCGTTATCACCCCGCTGGATATTTGA'\n",
        "\n",
        "dna_wt = dna_wt.upper()\n",
        "dna_gs = dna_gs.upper()\n",
        "\n",
        "dnas = {f'{protein_name}-WT': dna_wt, f'{protein_name}-GS': dna_gs}\n",
        "\n",
        "exec_func = {\n",
        "    'Exec SCG Model': True,\n",
        "    'Exec DNA Feature': True,\n",
        "    'Exec DNABERT-2 Model': True,\n",
        "    'Exec Sklearn model': True,\n",
        "    'Exec CNN-N-NF model': True\n",
        "}\n",
        "\n",
        "# beam search para\n",
        "beam_batch_sizes, beam_widths, beam_sizes = [4], [5], [8]\n",
        "# beam_batch_sizes, beam_widths = [1, 2, 4, 8, 16, 32], [2, 2, 3, 4, 5, 5]\n",
        "# beam_sizes = [val * 20 for val in beam_batch_sizes]\n",
        "\n",
        "# Sorting by the predictions of the first model, [0, 3]\n",
        "model_id = 0\n",
        "\n",
        "# Res dir\n",
        "res_dir = 'scg-gelp-res'\n",
        "if not os.path.exists(res_dir):\n",
        "    os.makedirs(res_dir)\n",
        "\n",
        "is_test = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40291aac",
      "metadata": {
        "id": "40291aac"
      },
      "source": [
        "## SCG-Transformer model to generate synonymous codon sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "143f9ce9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.258803Z",
          "start_time": "2024-06-18T13:46:11.254491Z"
        },
        "code_folding": [
          0
        ],
        "id": "143f9ce9"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed=42):\n",
        "    \"\"\" Set random seeds. \"\"\"\n",
        "\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "98e9fb22",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.267435Z",
          "start_time": "2024-06-18T13:46:11.261628Z"
        },
        "code_folding": [
          0
        ],
        "id": "98e9fb22"
      },
      "outputs": [],
      "source": [
        "class Vocab:\n",
        "    \"\"\" Dictionary of amino acid and nucleotide sequence encoding. \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        # Define special symbols and indices\n",
        "        UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "\n",
        "        # Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "        special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "        \"\"\"\n",
        "        self.token2id = {}\n",
        "        self.id2token = {}\n",
        "        self.count = 0  # For assigning unique identifiers\n",
        "        self.unk_token = '<unk>'\n",
        "\n",
        "    def init(self, seqs, token_type, special_tokens=['<unk>', '<pad>', '<bos>', '<eos>']):\n",
        "        self.token2id = {}\n",
        "        self.id2token = {}\n",
        "        self.count = 0\n",
        "\n",
        "        # Adding a special marking\n",
        "        if special_tokens:\n",
        "            for token in special_tokens:\n",
        "                self.add_token(token)\n",
        "\n",
        "        # Segmenting the token\n",
        "        if token_type == 'dna':\n",
        "            tokens =  [seq[i: i+3] for seq in seqs for i in range(0, len(seq), 3)]\n",
        "        elif token_type == 'protein':\n",
        "            tokens = [token for seq in seqs for token in seq]\n",
        "\n",
        "        # Sort by token frequency\n",
        "        counter = collections.Counter(tokens)\n",
        "        token_freqs = sorted(counter.items(),\n",
        "                                   key=lambda x: x[1],\n",
        "                                   reverse=True)\n",
        "\n",
        "        # Adding a Glossary\n",
        "        for token, _ in token_freqs:\n",
        "            if token not in self.token2id:\n",
        "                self.token2id[token] = self.count\n",
        "                self.id2token[self.count] = token\n",
        "                self.count += 1\n",
        "\n",
        "    def add_token(self, token):\n",
        "        if token not in self.token2id:\n",
        "            self.token2id[token] = self.count\n",
        "            self.id2token[self.count] = token\n",
        "            self.count += 1\n",
        "\n",
        "    def tokens_to_ids(self, tokens):\n",
        "        return [self.token2id.get(token, 0) for token in tokens]\n",
        "\n",
        "    def ids_to_tokens(self, ids):\n",
        "        return [self.id2token.get(str(_id), self.unk_token) for _id in ids]\n",
        "\n",
        "    def save(self, vocab_path):\n",
        "        res = {\n",
        "            'token2id': self.token2id,\n",
        "            'id2token': self.id2token,\n",
        "        }\n",
        "\n",
        "        with open(vocab_path, 'w', encoding='utf-8') as json_file:\n",
        "            json.dump(res, json_file)\n",
        "\n",
        "\n",
        "    def load(self, vocab_path):\n",
        "        with open(vocab_path, 'r') as json_file:\n",
        "            loaded_data = json.load(json_file)\n",
        "\n",
        "        self.token2id = loaded_data['token2id']\n",
        "        self.id2token = loaded_data['id2token']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token2id)\n",
        "\n",
        "    def __str__(self):\n",
        "        return str(list(self.token2id.items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e8f4fd07",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.272526Z",
          "start_time": "2024-06-18T13:46:11.268386Z"
        },
        "code_folding": [
          0
        ],
        "id": "e8f4fd07"
      },
      "outputs": [],
      "source": [
        "def get_vocab(protein_vocab_path, dna_vocab_path, log_info=True):\n",
        "    if not os.path.exists(protein_vocab_path):\n",
        "        raise ValueError('No file')\n",
        "    if not os.path.exists(dna_vocab_path):\n",
        "        raise ValueError('No file')\n",
        "\n",
        "    protein_vocab, dna_vocab = Vocab(), Vocab()\n",
        "    protein_vocab.load(protein_vocab_path)\n",
        "    dna_vocab.load(dna_vocab_path)\n",
        "\n",
        "    if log_info:\n",
        "        print(protein_vocab_path)\n",
        "        print(dna_vocab_path)\n",
        "\n",
        "        print(f'Vocab: {len(protein_vocab)}, {len(dna_vocab)}')\n",
        "        print(protein_vocab, dna_vocab)\n",
        "\n",
        "    return protein_vocab, dna_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6fef7c81",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.277596Z",
          "start_time": "2024-06-18T13:46:11.273400Z"
        },
        "code_folding": [
          0
        ],
        "id": "6fef7c81"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout, max_len=5000, device='cpu'):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Initialize shape to pe (positional encoding) of (max_len, d_model)\n",
        "        pe = torch.zeros(max_len, d_model).to(device)\n",
        "\n",
        "        # Initialize tensor [[0, 1, 2, 3, ...]]\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "\n",
        "        # Here is what is in the sin and cos brackets, transformed by e and ln\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
        "        )\n",
        "\n",
        "        # Calculate PE(pos, 2i)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "\n",
        "        # Calculate PE(pos, 2i+1)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # For ease of calculation, a batch at the outermost in unsqueeze out the\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # If a parameter doesn't participate in gradient descent but you want to save the mod save it\n",
        "        # This time you can use register_buffer\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x is the inputs after embedding, e.g. (1,7, 128), batch size is 1, 7 words, word dimension is 128\n",
        "        \"\"\"\n",
        "        # Adds x and positional encoding\n",
        "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e30939f5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.283663Z",
          "start_time": "2024-06-18T13:46:11.278592Z"
        },
        "code_folding": [
          0
        ],
        "id": "e30939f5"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    SCG-Transformer Network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1,\n",
        "                 max_length: int = 5000,\n",
        "                 pad_idx: int = 1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "\n",
        "        # Define embedding\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, emb_size, padding_idx=pad_idx)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, emb_size, padding_idx=pad_idx)\n",
        "\n",
        "        # Define posintional encoding\n",
        "        self.positional_encoding = PositionalEncoding(emb_size, dropout, max_len=max_length)\n",
        "\n",
        "        # Define model\n",
        "        self.transformer = nn.Transformer(d_model=emb_size,\n",
        "                                       nhead=nhead,\n",
        "                                       num_encoder_layers=num_encoder_layers,\n",
        "                                       num_decoder_layers=num_decoder_layers,\n",
        "                                       dim_feedforward=dim_feedforward,\n",
        "                                       dropout=dropout,\n",
        "                                       batch_first=True)\n",
        "\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                tgt: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        # Encoding of src and tgt\n",
        "        src = self.src_embedding(src)\n",
        "        tgt = self.tgt_embedding(tgt)\n",
        "\n",
        "        # Adding location information to src and tgt tokens\n",
        "        src = self.positional_encoding(src)\n",
        "        tgt = self.positional_encoding(tgt)\n",
        "\n",
        "        outs = self.transformer(src, tgt, src_mask, tgt_mask, None,\n",
        "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
        "\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        src = self.src_embedding(src)\n",
        "        src = self.positional_encoding(src)\n",
        "\n",
        "        return self.transformer.encoder(src, src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        tgt = self.tgt_embedding(tgt)\n",
        "        tgt = self.positional_encoding(tgt)\n",
        "\n",
        "        return self.transformer.decoder(tgt, memory, tgt_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6597a464",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.288473Z",
          "start_time": "2024-06-18T13:46:11.284603Z"
        },
        "code_folding": [
          0,
          6
        ],
        "id": "6597a464"
      },
      "outputs": [],
      "source": [
        "def generate_square_subsequent_mask(sz, device):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == False, float('-inf')).masked_fill(mask == True, float(0.0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "def create_mask(src, tgt, pad_idx, device):\n",
        "    src_seq_len = src.shape[-1]\n",
        "    tgt_seq_len = tgt.shape[-1]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len, device)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=device).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == pad_idx)\n",
        "    tgt_padding_mask = (tgt == pad_idx)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e591f33a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.293781Z",
          "start_time": "2024-06-18T13:46:11.289358Z"
        },
        "code_folding": [
          0
        ],
        "id": "e591f33a"
      },
      "outputs": [],
      "source": [
        "# Dictionary of amino acid codons with corresponding amino acids\n",
        "codon_table = {\n",
        "    'ATA': 'I', 'ATC': 'I', 'ATT': 'I', 'ATG': 'M',\n",
        "    'ACA': 'T', 'ACC': 'T', 'ACG': 'T', 'ACT': 'T',\n",
        "    'AAC': 'N', 'AAT': 'N', 'AAA': 'K', 'AAG': 'K',\n",
        "    'AGC': 'S', 'AGT': 'S', 'AGA': 'R', 'AGG': 'R',\n",
        "    'CTA': 'L', 'CTC': 'L', 'CTG': 'L', 'CTT': 'L',\n",
        "    'CCA': 'P', 'CCC': 'P', 'CCG': 'P', 'CCT': 'P',\n",
        "    'CAC': 'H', 'CAT': 'H', 'CAA': 'Q', 'CAG': 'Q',\n",
        "    'CGA': 'R', 'CGC': 'R', 'CGG': 'R', 'CGT': 'R',\n",
        "    'GTA': 'V', 'GTC': 'V', 'GTG': 'V', 'GTT': 'V',\n",
        "    'GCA': 'A', 'GCC': 'A', 'GCG': 'A', 'GCT': 'A',\n",
        "    'GAC': 'D', 'GAT': 'D', 'GAA': 'E', 'GAG': 'E',\n",
        "    'GGA': 'G', 'GGC': 'G', 'GGG': 'G', 'GGT': 'G',\n",
        "    'TCA': 'S', 'TCC': 'S', 'TCG': 'S', 'TCT': 'S',\n",
        "    'TTC': 'F', 'TTT': 'F', 'TTA': 'L', 'TTG': 'L',\n",
        "    'TAC': 'Y', 'TAT': 'Y', 'TAA': '*', 'TAG': '*',\n",
        "    'TGC': 'C', 'TGT': 'C', 'TGA': '*', 'TGG': 'W',\n",
        "}\n",
        "\n",
        "def translate_dna_to_protein(dna_sequence):\n",
        "    protein_sequence = ''\n",
        "    for i in range(0, len(dna_sequence), 3):\n",
        "        codon = dna_sequence[i:i+3].upper()\n",
        "        if codon in codon_table:\n",
        "            protein_sequence += codon_table[codon]\n",
        "        else:\n",
        "            protein_sequence += 'X'  # Unknown codons are denoted by X\n",
        "    return protein_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1826177e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.303565Z",
          "start_time": "2024-06-18T13:46:11.294749Z"
        },
        "code_folding": [
          0
        ],
        "id": "1826177e"
      },
      "outputs": [],
      "source": [
        "def translate_single_beam_search_decode(model, src, src_vocab, tgt_vocab, batch_size, beam_width, beam_size, device):\n",
        "    \"\"\"\n",
        "    function to generate output sequence ..\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    src_tokens = ['<bos>'] + list(src) + ['<eos>']\n",
        "    src_tokenizer = src_vocab.tokens_to_ids(src_tokens)\n",
        "    src = torch.tensor(src_tokenizer).unsqueeze(0).to(device)\n",
        "\n",
        "    # mask\n",
        "    src_len = len(src_tokens)\n",
        "    src_mask = torch.zeros((src_len, src_len), device=device).type(torch.bool)\n",
        "\n",
        "    pad_idx = src_vocab.token2id['<pad>']\n",
        "    src_padding_mask = (src == pad_idx)\n",
        "\n",
        "    src = src.to(device)\n",
        "    src_mask = src_mask.to(device)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "\n",
        "    tgt_bos, tgt_eos = tgt_vocab.token2id['<bos>'], tgt_vocab.token2id['<eos>']\n",
        "    tgt = torch.ones(1, 1).fill_(tgt_bos).type(torch.long).to(device)\n",
        "\n",
        "    # Use a queue to maintain the current state in the beam: sequence results, scores, whether it's finished or not\n",
        "    beam_queue = [(tgt, 0, False)]\n",
        "\n",
        "    # Use set to store states that have been traversed\n",
        "    explored_states = set()\n",
        "\n",
        "    count = 0\n",
        "    for i in tqdm(range(1, len(src_tokens))):\n",
        "\n",
        "        next_beam_queue = []\n",
        "        seen_tgt = set()\n",
        "\n",
        "        bq_len = len(beam_queue)\n",
        "        for bq_start_i in range(0, bq_len, batch_size):\n",
        "            bq_end_i = bq_start_i + batch_size\n",
        "            if bq_end_i > bq_len:\n",
        "                bq_end_i = bq_end_i\n",
        "\n",
        "            sub_beam_queue = beam_queue[bq_start_i: bq_end_i]\n",
        "\n",
        "            tgt_bs = []\n",
        "            score_bs = []\n",
        "            state_bs = []\n",
        "\n",
        "            for (tgt, score, state) in sub_beam_queue:\n",
        "                tgt_bs.append(tgt)\n",
        "                score_bs.append(score)\n",
        "                state_bs.append(state)\n",
        "\n",
        "            tgt_mask = (generate_square_subsequent_mask(tgt.size(-1), device)\n",
        "                        .type(torch.bool))\n",
        "\n",
        "            tgt_bs = torch.cat(tgt_bs, dim=0).to(device)\n",
        "\n",
        "            memory_bs = memory.repeat(len(sub_beam_queue), 1, 1).to(device)\n",
        "\n",
        "            out = model.decode(tgt_bs, memory_bs, tgt_mask)\n",
        "\n",
        "            # Predict the result, taking `out[:, -1]` since only the last word needs to be looked at\n",
        "            probs = model.generator(out[:, -1])\n",
        "\n",
        "            for tgt, prob, score, state in zip(tgt_bs, probs, score_bs, state_bs):\n",
        "                # Get the top k candidates and their corresponding probabilities, and get the optimal result of beam_width for the current prediction\n",
        "                topk_probs, topk_indices = torch.topk(prob, k=beam_width, dim=-1)\n",
        "\n",
        "                # Processing of each candidate word\n",
        "                for k in range(beam_width):\n",
        "                    next_tgt = torch.cat([tgt, topk_indices[k].unsqueeze(0)], dim=-1)\n",
        "                    next_tgt = next_tgt.unsqueeze(0)\n",
        "\n",
        "                    # de-emphasize\n",
        "                    if next_tgt in seen_tgt:\n",
        "                        continue\n",
        "\n",
        "                    # Calculate the new score, here cumulative probability\n",
        "                    next_score = score + topk_probs[k].item()\n",
        "\n",
        "                    # Check the last character\n",
        "                    end_char_id = topk_indices[k].item()\n",
        "\n",
        "                    # end char id -> 3 nucle char -> acid char -> acid id\n",
        "                    if end_char_id != tgt_eos:\n",
        "                        nucle_char = tgt_vocab.id2token[str(end_char_id)]\n",
        "                        if nucle_char in ['<unk>', '<bos>', '<eos>', '<pad>']:\n",
        "                            acid_char = nucle_char\n",
        "                        else:\n",
        "                            acid_char = codon_table[nucle_char]\n",
        "\n",
        "                        next_state = False\n",
        "                    else:\n",
        "                        acid_char = '<eos>'\n",
        "\n",
        "                        next_state = True\n",
        "\n",
        "                    # The predicted character is not the original amino acid to be excluded\n",
        "                    if acid_char != src_tokens[i]:\n",
        "                        continue\n",
        "\n",
        "                    # Take the optimal set of results\n",
        "                    seen_tgt.add(next_tgt)\n",
        "                    next_beam_queue.append((next_tgt, next_score, next_state))\n",
        "                    if len(next_beam_queue) > beam_size:\n",
        "                        next_beam_queue = sorted(next_beam_queue, key=lambda x: x[1], reverse=True)\n",
        "                        next_beam_queue = next_beam_queue[:beam_size]\n",
        "\n",
        "        # Update the current beam queue\n",
        "        beam_queue = next_beam_queue\n",
        "\n",
        "        # Check if all beams have reached the end condition\n",
        "        tag = True\n",
        "        for (tgt, score, state) in beam_queue:\n",
        "            # 所有都达到了 eos\n",
        "            if not (state == True or tgt.size(-1) >= len(src_tokens)) :\n",
        "                tag = False\n",
        "                break\n",
        "\n",
        "        if tag:\n",
        "            break\n",
        "\n",
        "    #\n",
        "    res = []\n",
        "    for (tgt, score, state) in beam_queue:\n",
        "        tgt = tgt.tolist()\n",
        "\n",
        "        # Access to forecasts\n",
        "        tgt = tgt[0]\n",
        "\n",
        "        # ID 2 token\n",
        "        tgt = tgt_vocab.ids_to_tokens(tgt)\n",
        "\n",
        "        # Splice results\n",
        "        tgt = ''.join(tgt)\n",
        "\n",
        "        # Remove start and stop characters\n",
        "        tgt = tgt.replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
        "\n",
        "        res.append(tgt)\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "419f1770",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.311393Z",
          "start_time": "2024-06-18T13:46:11.306023Z"
        },
        "code_folding": [
          0
        ],
        "id": "419f1770"
      },
      "outputs": [],
      "source": [
        "def SCG_Transformer_predict(protein_seq, beam_batch_sizes, beam_widths, beam_sizes):\n",
        "    # 1 file\n",
        "\n",
        "    # data\n",
        "    protein_vocab_path = f'{resource_dir}/ref_vocab_protein.json'\n",
        "    dna_vocab_path = f'{resource_dir}/ref_vocab_dna.json'\n",
        "\n",
        "    ref_dataset_tag = '6'\n",
        "#     train_fasta_json = f'{resource_dir}/ref_e.coli_{ref_dataset_tag}.json'\n",
        "\n",
        "    # hyper-parameters\n",
        "#     resume = True\n",
        "#     training = True\n",
        "#     predict = not training\n",
        "\n",
        "    PAD_IDX = 1  # UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "\n",
        "    batch_size = 16\n",
        "\n",
        "    lr = 0.0001\n",
        "\n",
        "    curr_epoch = 1\n",
        "    num_epoch = 600\n",
        "\n",
        "    last_loss = 1e10\n",
        "\n",
        "    # model\n",
        "    d_model = 512\n",
        "    nhead = 8\n",
        "    num_encoder_layers = 3\n",
        "    num_decoder_layers = 3\n",
        "    dim_feedforward = 512\n",
        "    dropout = 0.1\n",
        "    max_length = 1024\n",
        "    # max_length = 2048\n",
        "\n",
        "    tag = f'tf_{lr}_{d_model}_{nhead}_{num_encoder_layers}_{num_decoder_layers}_{dim_feedforward}_{dropout}_{max_length}_{ref_dataset_tag}'\n",
        "\n",
        "    checkpoint_path = f'{resource_dir}/{tag}.pt'\n",
        "    print(f'modle: {checkpoint_path}')\n",
        "\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        raise\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'device: {device}')\n",
        "\n",
        "    # 2 vocab\n",
        "    log_info = False\n",
        "    protein_vocab, dna_vocab = get_vocab(protein_vocab_path, dna_vocab_path, log_info=log_info)\n",
        "\n",
        "    # 4 model\n",
        "    model = Seq2SeqTransformer(len(protein_vocab), len(dna_vocab),\n",
        "                                     emb_size=d_model, nhead=nhead,\n",
        "                                     num_encoder_layers=num_encoder_layers, num_decoder_layers=num_decoder_layers,\n",
        "                                     dim_feedforward=dim_feedforward, dropout=dropout,\n",
        "                                     max_length=max_length, pad_idx=PAD_IDX)\n",
        "\n",
        "    # need memory\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "    curr_epoch = checkpoint['epoch'] + 1\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    last_loss = checkpoint['loss']\n",
        "\n",
        "    print(f'resume train: epoch {curr_epoch}, loss {last_loss}')\n",
        "\n",
        "    # to device\n",
        "    model = model.to(device)\n",
        "    print(print(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
        "\n",
        "    # main\n",
        "    dnas_s = set()\n",
        "\n",
        "    print('beam search args:', beam_batch_sizes, beam_widths, beam_sizes)\n",
        "    for beam_batch_size, beam_width, beam_size in zip(beam_batch_sizes, beam_widths, beam_sizes):\n",
        "        print('args:', beam_batch_size, beam_width, beam_size)\n",
        "        dnas = translate_single_beam_search_decode(model, protein_seq, protein_vocab, dna_vocab, beam_batch_size, beam_width, beam_size, device)\n",
        "\n",
        "        for d in dnas:\n",
        "            dnas_s.add(d)\n",
        "\n",
        "    dnas = list(dnas_s)\n",
        "\n",
        "    print('SCG return dna num:', len(dnas))\n",
        "\n",
        "    return dnas\n",
        "\n",
        "# raise"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_test = True"
      ],
      "metadata": {
        "id": "hbSiDKPUCwO6"
      },
      "id": "hbSiDKPUCwO6",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "743318ee",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.315778Z",
          "start_time": "2024-06-18T13:46:11.312355Z"
        },
        "code_folding": [],
        "id": "743318ee",
        "outputId": "4abd687b-a443-42dc-fab6-dafdc6034d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "18f6e7693df54a38a068922f5980b5b5",
            "b4362077d4f64df5ba781f1f47edd4e1",
            "7ed63e680105458db59b6b37eb91c5b6",
            "ec99b2f3c7ea4d19873076be93fbc095",
            "131e7361c76c4b02bc71add3f1861e31",
            "05cff9428f8f4d4d9799b257b9e1cac9",
            "bd71c110477342139ae439b46527b140",
            "368911d2e48542e0a2504c4f6edc4245",
            "637e744961a8488886c3e2410b868721",
            "5b4e60a9e1cb4f19aa516b1628e5fabe",
            "c3e70e8c739a4c32a8127bc864a26226"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "modle: /content/SCG-GELP/tf_0.0001_512_8_3_3_512_0.1_1024_6.pt\n",
            "device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-a35e589a1a82>:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resume train: epoch 47, loss 0.9707116135501553\n",
            "12707396\n",
            "None\n",
            "beam search args: [4] [5] [8]\n",
            "args: 4 5 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/239 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18f6e7693df54a38a068922f5980b5b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCG return dna num: 8\n",
            "['ATGAGAATAATAAATGTAAAAGATTATGAAGAGATGTCAAGAAAAGCAGCAGATTTAATTGCTGCTCAAATTATTTTAAATCCTAAAAGTTCTCTTGGTTTAGCTCATGGTAAAAGTCCTATTGGTTTTTATGAACGTTTAGTTGAATTAAATCGTAATGGTGTTATTGATTTTAGTCATGTAACAACAATTAATTTAGATGAATATTATGGTTTAGATCCTACTCATGATCAAAGTTATCGTTATTTTATGAATAAGCATTTATTTAGTCGTGTGAATATTAATATGGCAAATACACATTTACCAGATGGTAAAGCAAAAGATATTGATGCTGAATGTATTCGTTATGATGATTTGATTGAAAGTGTTGGTGGTATTGATTTACAGTTATTAGGTATTGGTCATAATGGTCATATTTTCTTTAATGAACCAAGTGATGAATTTATTCCAGGTACACATTGTGTTTCTTTATCACAAAGTACAATTAATGCAAATAGTTTAATGTATTTTTCTCGTGATGAAGTACAACGTAAAGCAATTACTATGGGTATTAAAGCCATTATGCAAGCTCGTTATGTACAGTTAATTGCTAGTGGTGAAGACCAAATTGAAATTTTAAAAAAAGCATTATTTGGCCCAATTACACCACAAGTACCAGCATCTATTTTACAATTACATAAAGATTTAACAGTAATTACACCATTAGATATTTAA', 'ATGAGAATAATAAATGTAAAAGATTATGAAGAGATGTCAAGAAAAGCAGCAGATTTAATTGCTGCTCAAATTATTTTAAATCCTAAAAGTTCTCTTGGTTTAGCTCATGGTAAAAGTCCTATTGGTTTTTATGAACGTTTAGTTGAATTAAATCGTAATGGTGTTATTGATTTTAGTCATGTAACAACAATTAATTTAGATGAATATTATGGTTTAGATCCTACTCATGATCAAAGTTATCGTTATTTTATGAATAAGCATTTATTTAGTCGTGTGAATATTAATATGGCAAATACACATTTACCAGATGGTAAAGCAAAAGATATTGATGCTGAATGTATTCGTTATGATGATTTGATTGAAAGTGTTGGTGGTATTGATTTACAGTTATTAGGTATTGGTCATAATGGTCATATTTTCTTTAATGAACCAAGTGATGAATTTATTCCAGGTACACATTGTGTTTCTTTATCACAAAGTACAATTAATGCAAATAGTTTAATGTATTTTTCTCGTGATGAAGTACAACGTAAAGCAATTACTATGGGTATTAAAGCCATTATGCAAGCTCGTTATGTACAGTTAATTGCTAGTGGTGAAGACCAAATTGAAATTTTAAAAAAAGCATTATTTGGCCCAATTACACCACAAGTACCTGCTTCTATTTTACAATTACATAAAGATTTAACAGTAATTACACCATTAGATATTTAA', 'ATGAGAATAATAAATGTAAAAGATTATGAAGAGATGTCAAGAAAAGCAGCAGATTTAATTGCTGCTCAAATTATTTTAAATCCTAAAAGTTCTCTTGGTTTAGCTCATGGTAAAAGTCCTATTGGTTTTTATGAACGTTTAGTTGAATTAAATCGTAATGGTGTTATTGATTTTAGTCATGTAACAACAATTAATTTAGATGAATATTATGGTTTAGATCCTACTCATGATCAAAGTTATCGTTATTTTATGAATAAGCATTTATTTAGTCGTGTGAATATTAATATGGCAAATACACATTTACCAGATGGTAAAGCAAAAGATATTGATGCTGAATGTATTCGTTATGATGATTTGATTGAAAGTGTTGGTGGTATTGATTTACAGTTATTAGGTATTGGTCATAATGGTCATATTTTCTTTAATGAACCAAGTGATGAATTTATTCCAGGTACACATTGTGTTTCTTTATCACAAAGTACAATTAATGCAAATAGTTTAATGTATTTTTCTCGTGATGAAGTACAACGTAAAGCAATTACTATGGGTATTAAAGCCATTATGCAAGCTCGTTATGTACAGTTAATTGCTAGTGGTGAAGACCAAATTGAAATTTTAAAAAAAGCATTATTTGGCCCAATTACACCACAAGTACCAGCATCAATTTTACAATTACATAAAGATTTAACAGTAATTACACCATTAGATATTTAA', 'ATGAGAATAATAAATGTAAAAGATTATGAAGAGATGTCAAGAAAAGCAGCAGATTTAATTGCTGCTCAAATTATTTTAAATCCTAAAAGTTCTCTTGGTTTAGCTCATGGTAAAAGTCCTATTGGTTTTTATGAACGTTTAGTTGAATTAAATCGTAATGGTGTTATTGATTTTAGTCATGTAACAACAATTAATTTAGATGAATATTATGGTTTAGATCCTACTCATGATCAAAGTTATCGTTATTTTATGAATAAGCATTTATTTAGTCGTGTGAATATTAATATGGCAAATACACATTTACCAGATGGTAAAGCAAAAGATATTGATGCTGAATGTATTCGTTATGATGATTTGATTGAAAGTGTTGGTGGTATTGATTTACAGTTATTAGGTATTGGTCATAATGGTCATATTTTCTTTAATGAACCAAGTGATGAATTTATTCCAGGTACACATTGTGTTTCTTTATCACAAAGTACAATTAATGCAAATAGTTTAATGTATTTTTCTCGTGATGAAGTACAACGTAAAGCAATTACTATGGGTATTAAAGCCATTATGCAAGCTCGTTATGTACAGTTAATTGCTAGTGGTGAAGATCAAATTGAAATTTTAAAAAAAGCATTATTTGGCCCAATTACACCACAAGTACCAGCATCAATTTTACAATTACATAAAGATTTAACAGTAATTACACCATTAGATATTTAA', 'ATGAGAATAATAAATGTAAAAGATTATGAAGAGATGTCAAGAAAAGCAGCAGATTTAATTGCTGCTCAAATTATTTTAAATCCTAAAAGTTCTCTTGGTTTAGCTCATGGTAAAAGTCCTATTGGTTTTTATGAACGTTTAGTTGAATTAAATCGTAATGGTGTTATTGATTTTAGTCATGTAACAACAATTAATTTAGATGAATATTATGGTTTAGATCCTACTCATGATCAAAGTTATCGTTATTTTATGAATAAGCATTTATTTAGTCGTGTGAATATTAATATGGCAAATACACATTTACCAGATGGTAAAGCAAAAGATATTGATGCTGAATGTATTCGTTATGATGATTTGATTGAAAGTGTTGGTGGTATTGATTTACAGTTATTAGGTATTGGTCATAATGGTCATATTTTCTTTAATGAACCAAGTGATGAATTTATTCCAGGTACACATTGTGTTTCTTTATCACAAAGTACAATTAATGCAAATAGTTTAATGTATTTTTCTCGTGATGAAGTACAACGTAAAGCAATTACTATGGGTATTAAAGCCATTATGCAAGCTCGTTATGTACAGTTAATTGCTAGTGGTGAAGATCAAATTGAAATTTTAAAAAAAGCATTATTTGGCCCAATTACACCACAAGTACCAGCATCTATTTTACAATTACATAAAGATTTAACAGTAATTACACCATTAGATATTTAA', 'ATGAGAATAATAAATGTAAAAGATTATGAAGAGATGTCAAGAAAAGCAGCAGATTTAATTGCTGCTCAAATTATTTTAAATCCTAAAAGTTCTCTTGGTTTAGCTCATGGTAAAAGTCCTATTGGTTTTTATGAACGTTTAGTTGAATTAAATCGTAATGGTGTTATTGATTTTAGTCATGTAACAACAATTAATTTAGATGAATATTATGGTTTAGATCCTACTCATGATCAAAGTTATCGTTATTTTATGAATAAGCATTTATTTAGTCGTGTGAATATTAATATGGCAAATACACATTTACCAGATGGTAAAGCAAAAGATATTGATGCTGAATGTATTCGTTATGATGATTTGATTGAAAGTGTTGGTGGTATTGATTTACAGTTATTAGGTATTGGTCATAATGGTCATATTTTCTTTAATGAACCAAGTGATGAATTTATTCCAGGTACACATTGTGTTTCTTTATCACAAAGTACAATTAATGCAAATAGTTTAATGTATTTTTCTCGTGATGAAGTACAACGTAAAGCAATTACTATGGGTATTAAAGCCATTATGCAAGCTCGTTATGTACAGTTAATTGCTAGTGGTGAAGACCAAATTGAAATTTTAAAAAAAGCATTATTTGGCCCAATTACACCACAAGTACCTGCATCAATTTTACAATTACATAAAGATTTAACAGTAATTACACCATTAGATATTTAA', 'ATGAGAATAATAAATGTAAAAGATTATGAAGAGATGTCAAGAAAAGCAGCAGATTTAATTGCTGCTCAAATTATTTTAAATCCTAAAAGTTCTCTTGGTTTAGCTCATGGTAAAAGTCCTATTGGTTTTTATGAACGTTTAGTTGAATTAAATCGTAATGGTGTTATTGATTTTAGTCATGTAACAACAATTAATTTAGATGAATATTATGGTTTAGATCCTACTCATGATCAAAGTTATCGTTATTTTATGAATAAGCATTTATTTAGTCGTGTGAATATTAATATGGCAAATACACATTTACCAGATGGTAAAGCAAAAGATATTGATGCTGAATGTATTCGTTATGATGATTTGATTGAAAGTGTTGGTGGTATTGATTTACAGTTATTAGGTATTGGTCATAATGGTCATATTTTCTTTAATGAACCAAGTGATGAATTTATTCCAGGTACACATTGTGTTTCTTTATCACAAAGTACAATTAATGCAAATAGTTTAATGTATTTTTCTCGTGATGAAGTACAACGTAAAGCAATTACTATGGGTATTAAAGCCATTATGCAAGCTCGTTATGTACAGTTAATTGCTAGTGGTGAAGACCAAATTGAAATTTTAAAAAAAGCATTATTTGGCCCAATTACACCACAAGTACCTGCTTCTATTTTACAACTACATAAAGATTTAACAGTAATTACACCATTAGATATTTAA', 'ATGAGAATAATAAATGTAAAAGATTATGAAGAGATGTCAAGAAAAGCAGCAGATTTAATTGCTGCTCAAATTATTTTAAATCCTAAAAGTTCTCTTGGTTTAGCTCATGGTAAAAGTCCTATTGGTTTTTATGAACGTTTAGTTGAATTAAATCGTAATGGTGTTATTGATTTTAGTCATGTAACAACAATTAATTTAGATGAATATTATGGTTTAGATCCTACTCATGATCAAAGTTATCGTTATTTTATGAATAAGCATTTATTTAGTCGTGTGAATATTAATATGGCAAATACACATTTACCAGATGGTAAAGCAAAAGATATTGATGCTGAATGTATTCGTTATGATGATTTGATTGAAAGTGTTGGTGGTATTGATTTACAGTTATTAGGTATTGGTCATAATGGTCATATTTTCTTTAATGAACCAAGTGATGAATTTATTCCAGGTACACATTGTGTTTCTTTATCACAAAGTACAATTAATGCAAATAGTTTAATGTATTTTTCTCGTGATGAAGTACAACGTAAAGCAATTACTATGGGTATTAAAGCCATTATGCAAGCTCGTTATGTACAGTTAATTGCTAGTGGTGAAGACCAAATTGAAATTTTAAAAAAAGCATTATTTGGCCCAATTACACCACAAGTACCTGCTTCAATTTTACAATTACATAAAGATTTAACAGTAATTACACCATTAGATATTTAA']\n"
          ]
        }
      ],
      "source": [
        "if is_test:\n",
        "    # Test SCG-Transformer model\n",
        "    dnas = SCG_Transformer_predict(protein_seq, beam_batch_sizes, beam_widths, beam_sizes)\n",
        "    print(dnas)\n",
        "    # for DNABERT-2\n",
        "    dna_file = f'{res_dir}/{protein_name}_scg_dnas_test.csv'\n",
        "\n",
        "    with open(dna_file, 'w', encoding='utf-8') as w:\n",
        "        w.write('name,nucle-seq,label\\n')\n",
        "        for i, dna in enumerate(dnas):\n",
        "            w.write(f'scg_{i},{dna},-1\\n')\n",
        "\n",
        "#     raise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e89aa55",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-28T07:23:41.908361Z",
          "start_time": "2024-01-28T07:23:41.905575Z"
        },
        "id": "7e89aa55"
      },
      "source": [
        "## Biological features and transfer learning (DNABER-2) feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a833ed6b",
      "metadata": {
        "id": "a833ed6b"
      },
      "source": [
        "### Biological features extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "843940ff",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.471469Z",
          "start_time": "2024-06-18T13:46:11.316968Z"
        },
        "code_folding": [
          0
        ],
        "id": "843940ff"
      },
      "outputs": [],
      "source": [
        "#\n",
        "def KmerArray(seq, k, is_sort=False):\n",
        "    if not is_sort:\n",
        "        return [seq[i:i + k] for i in range(len(seq) - k + 1)]\n",
        "    else:\n",
        "        return [''.join(sorted(seq[i:i + k])) for i in range(len(seq) - k + 1)]\n",
        "\n",
        "\n",
        "def Kmer(sequence):\n",
        "    \"\"\"\n",
        "    return 1 x 64\n",
        "    \"\"\"\n",
        "    kmer_n = 3\n",
        "\n",
        "    NA = 'ACGT'\n",
        "\n",
        "    # 64 个密码子\n",
        "    kmer_name = [\n",
        "        ''.join(item) for item in itertools.product(NA, repeat=kmer_n)\n",
        "    ]\n",
        "\n",
        "    # 根据 Kmer 分割 子序列\n",
        "    kmer_array = KmerArray(sequence, kmer_n)\n",
        "    #     print(kmer_array[:3])\n",
        "\n",
        "    # 统计\n",
        "    count = Counter(kmer_array)\n",
        "    #     print(count)\n",
        "\n",
        "    # normalized\n",
        "    kmer_num = float(len(kmer_array))\n",
        "    res = [count.get(key, 0) / kmer_num for key in kmer_name]\n",
        "    #     print(res[:3])\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def RCKmer(sequence):\n",
        "    \"\"\"\n",
        "    return 1 x 32\n",
        "\n",
        "    替换掉一半密码子\n",
        "    \"\"\"\n",
        "    kmer_n = 3\n",
        "\n",
        "    NA = 'ACGT'\n",
        "\n",
        "    NA_dict = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'}\n",
        "\n",
        "    # 64 个密码子\n",
        "    kmer_name = [\n",
        "        ''.join(item) for item in itertools.product(NA, repeat=kmer_n)\n",
        "    ]\n",
        "\n",
        "    #\n",
        "    rc_kmer_name = set()\n",
        "    for kmer in kmer_name:\n",
        "        # a[::-1]，它会从末尾开始到第一个获取每个元素。所以它颠倒了a\n",
        "        rc_kmer_name.add(\n",
        "            sorted([kmer, ''.join([NA_dict[nc] for nc in kmer[::-1]])])[0])\n",
        "\n",
        "    rc_kmer_name = sorted(rc_kmer_name)\n",
        "\n",
        "    #\n",
        "    rc_kmer_dict = {}\n",
        "    for kmer in rc_kmer_name:\n",
        "        rc_kmer = ''.join([NA_dict[nc] for nc in kmer[::-1]])\n",
        "        if kmer != rc_kmer:\n",
        "            rc_kmer_dict[rc_kmer] = kmer\n",
        "\n",
        "    # 根据 Kmer 分割 子序列\n",
        "    kmer_array = KmerArray(sequence, kmer_n)\n",
        "\n",
        "    # 替换 掉 一半 的密码子\n",
        "    for i in range(len(kmer_array)):\n",
        "        key = kmer_array[i]\n",
        "        if key in rc_kmer_dict:\n",
        "            kmer_array[i] = rc_kmer_dict[key]\n",
        "\n",
        "    # 统计\n",
        "    count = Counter(kmer_array)\n",
        "\n",
        "    # normalized\n",
        "    kmer_num = float(len(kmer_array))\n",
        "    res = [count.get(key, 0) / kmer_num for key in sorted(rc_kmer_dict.values())]\n",
        "    #     print(res[:3])\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def Mismatch(sequence):\n",
        "    \"\"\"\n",
        "    return 1 x 64\n",
        "    \"\"\"\n",
        "    kmer_n = 3\n",
        "    mismatch = 1\n",
        "\n",
        "    NA = 'ACGT'\n",
        "\n",
        "    # 64 个密码子\n",
        "    kmer_name = [\n",
        "        ''.join(item) for item in itertools.product(NA, repeat=kmer_n)\n",
        "    ]\n",
        "\n",
        "    kmer_dict = dict.fromkeys(kmer_name, 0)\n",
        "\n",
        "    # 根据 Kmer 分割 子序列\n",
        "    kmer_array = KmerArray(sequence, kmer_n)\n",
        "    #     print(kmer_array[:3])\n",
        "\n",
        "    for kmer in kmer_array:\n",
        "        for key in kmer_dict:\n",
        "            mismatch_count = sum([\n",
        "                1 if kmer[i] != key[i] else 0\n",
        "                for i in range(min(len(kmer), len(key)))\n",
        "            ])\n",
        "            if mismatch_count <= mismatch:\n",
        "                kmer_dict[key] += 1\n",
        "\n",
        "    res = [kmer_dict[k] for k in sorted(kmer_dict.keys())]\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def CKSNAP(sequence):\n",
        "    \"\"\"\n",
        "    return 1 x 64\n",
        "    \"\"\"\n",
        "    kspace = 3\n",
        "    assert len(sequence) >= kspace + 2\n",
        "\n",
        "    NA = 'ACGT'\n",
        "\n",
        "    # 16 个\n",
        "    nn_name = [''.join(item) for item in itertools.product(NA, repeat=2)]\n",
        "\n",
        "    res = []\n",
        "    for ksp in range(kspace + 1):\n",
        "        count = len(sequence) - ksp - 1\n",
        "        nn_dict = dict.fromkeys(nn_name, 0)\n",
        "        for i in range(count):\n",
        "            nn_dict[sequence[i] + sequence[i + ksp + 1]] += 1\n",
        "\n",
        "        res += [nn_dict[k] / count for k in nn_dict]\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def PseEIIP(sequence):\n",
        "    \"\"\"\n",
        "    return 1 x 64\n",
        "    \"\"\"\n",
        "    NA = 'ACGT'\n",
        "\n",
        "    EIIP_dict = {\n",
        "        'A': 0.1260,\n",
        "        'C': 0.1340,\n",
        "        'G': 0.0806,\n",
        "        'T': 0.1335,\n",
        "    }\n",
        "\n",
        "    # 64 个\n",
        "    nn_name = [''.join(item) for item in itertools.product(NA, repeat=3)]\n",
        "\n",
        "    pse_dict = dict.fromkeys(nn_name, 0)\n",
        "    for k in pse_dict:\n",
        "        pse_dict[k] = sum([EIIP_dict[i] for i in k])\n",
        "\n",
        "    # 根据 Kmer 分割 子序列\n",
        "    kmer_array = KmerArray(sequence, 3)\n",
        "    #     print(kmer_array[:3])\n",
        "\n",
        "    # 统计\n",
        "    count = Counter(kmer_array)\n",
        "    #     print(count)\n",
        "\n",
        "    # normalized\n",
        "    kmer_num = float(len(kmer_array))\n",
        "    res = [pse_dict[key] * count.get(key, 0) / kmer_num for key in nn_name]\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def PCP(sequence, kmer_n, dna_property_dict):\n",
        "    NA = 'ACGT'\n",
        "\n",
        "    #     kmer_n = 2\n",
        "\n",
        "    # 统计 kmer_n 出现次数\n",
        "    nn_name = [''.join(item) for item in itertools.product(NA, repeat=kmer_n)]\n",
        "\n",
        "    nn_dict = dict.fromkeys(nn_name, 0)\n",
        "    for i in range(len(sequence) - kmer_n + 1):\n",
        "        nn_dict[sequence[i:i + kmer_n]] += 1\n",
        "\n",
        "    sum_val = sum(list(nn_dict.values()))\n",
        "    nn_val = [nn_dict[k] / sum_val for k in nn_name]\n",
        "\n",
        "    # 和预设值相乘\n",
        "    res = []\n",
        "    for k in dna_property_dict.keys():\n",
        "        res_ = np.multiply(nn_val, dna_property_dict[k])\n",
        "\n",
        "        res += list(res_)\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def DPCP(sequence):\n",
        "    \"\"\"\n",
        "    return 1 x 96(16*6)\n",
        "    \"\"\"\n",
        "    dna_property_dict = {\n",
        "        'Twist': [\n",
        "            0.063, 1.502, 0.783, 1.071, -1.376, 0.063, -1.664, 0.783, -0.081,\n",
        "            -0.081, 0.063, 1.502, -1.233, -0.081, -1.376, 0.063\n",
        "        ],\n",
        "        'Tilt': [\n",
        "            0.502, 0.502, 0.359, 0.215, -1.364, 1.077, -1.22, 0.359, 0.502,\n",
        "            0.215, 1.077, 0.502, -2.368, 0.502, -1.364, 0.502\n",
        "        ],\n",
        "        'Roll': [\n",
        "            0.09, 1.19, -0.28, 0.83, -1.01, -0.28, -1.38, -0.28, 0.09, 2.3,\n",
        "            -0.28, 1.19, -1.38, 0.09, -1.01, 0.09\n",
        "        ],\n",
        "        'Shift': [\n",
        "            1.587, 0.126, 0.679, -1.019, -0.861, 0.56, -0.822, 0.679, 0.126,\n",
        "            -0.348, 0.56, 0.126, -2.243, 0.126, -0.861, 1.587\n",
        "        ],\n",
        "        'Slide': [\n",
        "            0.111, 1.289, -0.241, 2.513, -0.623, -0.822, -0.287, -0.241,\n",
        "            -0.394, 0.646, -0.822, 1.289, -1.511, -0.394, -0.623, 0.111\n",
        "        ],\n",
        "        'Rise': [\n",
        "            -0.109, 1.044, -0.623, 1.171, -1.254, 0.242, -1.389, -0.623, 0.711,\n",
        "            1.585, 0.242, 1.044, -1.389, 0.711, -1.254, -0.109\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    kmer_n = 2\n",
        "    return PCP(sequence, kmer_n, dna_property_dict)\n",
        "\n",
        "\n",
        "def TPCP(sequence):\n",
        "    \"\"\"\n",
        "    return 1 x 768(64*12)\n",
        "    \"\"\"\n",
        "    dna_property_dict = {\n",
        "        'Bendability (DNAse)': [\n",
        "            -2.087, -1.509, -0.506, -2.126, 0.111, -0.121, -0.121, -1.354,\n",
        "            0.381, 0.304, -0.313, -1.354, 1.615, -0.737, 1.229, -2.126, 0.265,\n",
        "            0.496, 1.576, 1.229, -1.856, 0.072, -0.969, -0.313, 0.111, -0.468,\n",
        "            -0.969, -0.121, 0.882, 0.419, 1.576, -0.506, -0.159, 0.034, 0.419,\n",
        "            -0.737, 0.766, 1.036, -0.468, 0.304, 0.265, 1.036, 0.072, -0.121,\n",
        "            0.342, 0.034, 0.496, -1.509, 0.689, 0.342, 0.882, 1.615, 1.73,\n",
        "            0.265, 0.111, 0.381, 1.73, 0.766, -1.856, 0.111, 0.689, -0.159,\n",
        "            0.265, -2.087\n",
        "        ],\n",
        "        'Bendability (consensus)': [\n",
        "            -2.745, -1.354, -0.257, -2.585, 0.171, 0.064, 0.064, -0.685, -0.15,\n",
        "            0.92, -0.07, -0.685, 0.572, -0.391, 1.348, -2.585, -0.231, 0.786,\n",
        "            0.92, 1.348, -1.14, 0.358, -0.712, -0.07, 1.0, 0.385, -0.712,\n",
        "            0.064, -0.097, 0.438, 0.92, -0.257, -0.605, 0.171, 0.438, -0.391,\n",
        "            0.839, 2.097, 0.385, 0.92, -0.097, 2.097, 0.358, 0.064, -0.07,\n",
        "            0.171, 0.786, -1.354, -0.284, -0.07, -0.097, 0.572, 1.348, -0.097,\n",
        "            1.0, -0.15, 1.348, 0.839, -1.14, 0.171, -0.284, -0.605, -0.231,\n",
        "            -2.745\n",
        "        ],\n",
        "        'Trinucleotide GC Content': [\n",
        "            -1.732, -0.577, -0.577, -1.732, -0.577, 0.577, 0.577, -0.577,\n",
        "            -0.577, 0.577, 0.577, -0.577, -1.732, -0.577, -0.577, -1.732,\n",
        "            -0.577, 0.577, 0.577, -0.577, 0.577, 1.732, 1.732, 0.577, 0.577,\n",
        "            1.732, 1.732, 0.577, -0.577, 0.577, 0.577, -0.577, -0.577, 0.577,\n",
        "            0.577, -0.577, 0.577, 1.732, 1.732, 0.577, 0.577, 1.732, 1.732,\n",
        "            0.577, -0.577, 0.577, 0.577, -0.577, -1.732, -0.577, -0.577,\n",
        "            -1.732, -0.577, 0.577, 0.577, -0.577, -0.577, 0.577, 0.577, -0.577,\n",
        "            -1.732, -0.577, -0.577, -1.732\n",
        "        ],\n",
        "        'Nucleosome positioning': [\n",
        "            -2.349, -0.561, 0.155, -1.991, 0.155, 0.274, 0.274, 0.453, -0.74,\n",
        "            1.287, 0.274, 0.453, -0.978, 0.214, 0.87, -1.991, -0.74, 0.81,\n",
        "            -0.322, 0.87, 0.274, 0.572, -0.084, 0.274, 1.645, 1.287, -0.084,\n",
        "            0.274, -1.276, 0.274, -0.322, 0.155, -0.918, 0.274, 0.274, 0.214,\n",
        "            0.572, 2.479, 1.287, 1.287, -0.501, 2.479, 0.572, 0.274, -0.561,\n",
        "            0.274, 0.81, -0.561, -1.395, -0.561, -1.276, -0.978, 0.274, -0.501,\n",
        "            1.645, -0.74, 0.274, 0.572, 0.274, 0.155, -1.395, -0.918, -0.74,\n",
        "            -2.349\n",
        "        ],\n",
        "        'Consensus_roll': [\n",
        "            -2.744, -1.363, -0.26, -2.591, 0.164, 0.071, 0.065, -0.676, -0.158,\n",
        "            0.911, -0.07, -0.676, 0.584, -0.397, 1.358, -2.591, -0.226, 0.773,\n",
        "            0.92, 1.358, -1.139, 0.345, -0.705, -0.07, 1.012, 0.379, -0.705,\n",
        "            0.065, -0.097, 0.427, 0.92, -0.26, -0.6, 0.178, 0.427, -0.397,\n",
        "            0.842, 2.089, 0.379, 0.911, -0.103, 2.089, 0.345, 0.071, -0.062,\n",
        "            0.178, 0.773, -1.363, -0.275, -0.062, -0.097, 0.584, 1.348, -0.103,\n",
        "            1.012, -0.158, 1.348, 0.842, -1.139, 0.164, -0.275, -0.6, -0.226,\n",
        "            -2.744\n",
        "        ],\n",
        "        'Consensus-Rigid': [\n",
        "            -2.744, -1.363, -0.26, -2.591, 0.164, 0.071, 0.065, -0.676, -0.158,\n",
        "            0.911, -0.07, -0.676, 0.584, -0.397, 1.358, -2.591, -0.226, 0.773,\n",
        "            0.92, 1.358, -1.139, 0.345, -0.705, -0.07, 1.012, 0.379, -0.705,\n",
        "            0.065, -0.097, 0.427, 0.92, -0.26, -0.6, 0.178, 0.427, -0.397,\n",
        "            0.842, 2.089, 0.379, 0.911, -0.103, 2.089, 0.345, 0.071, -0.062,\n",
        "            0.178, 0.773, -1.363, -0.275, -0.062, -0.097, 0.584, 1.348, -0.103,\n",
        "            1.012, -0.158, 1.348, 0.842, -1.139, 0.164, -0.275, -0.6, -0.226,\n",
        "            -2.744\n",
        "        ],\n",
        "        'Dnase I': [\n",
        "            2.274, 1.105, 0.193, 2.141, -0.153, -0.078, -0.074, 0.536, 0.109,\n",
        "            -0.753, 0.039, 0.536, -0.491, 0.307, -1.112, 2.141, 0.166, -0.646,\n",
        "            -0.762, -1.112, 0.917, -0.3, 0.558, 0.039, -0.834, -0.326, 0.558,\n",
        "            -0.074, 0.062, -0.365, -0.762, 0.193, 0.474, -0.165, -0.365, 0.307,\n",
        "            -0.702, -1.687, -0.326, -0.753, 0.066, -1.687, -0.3, -0.078, 0.031,\n",
        "            -0.165, -0.646, 1.105, 0.206, 0.031, 0.062, -0.491, -1.103, 0.066,\n",
        "            -0.834, 0.109, 4.522, -0.702, 0.917, -0.153, 0.206, 0.474, 0.166,\n",
        "            -2.615\n",
        "        ],\n",
        "        'Dnase I-Rigid': [\n",
        "            2.118, 1.516, 0.493, 2.158, -0.123, 0.107, 0.107, 1.357, -0.389,\n",
        "            -0.313, 0.3, 1.357, -1.585, 0.727, -1.215, 2.158, -0.275, -0.503,\n",
        "            -1.549, -1.215, 1.876, -0.084, 0.962, 0.3, -0.123, 0.455, 0.962,\n",
        "            0.107, -0.88, -0.427, -1.549, 0.493, 0.146, -0.046, -0.427, 0.727,\n",
        "            -0.767, -1.029, 0.455, -0.313, -0.275, -1.029, -0.084, 0.107,\n",
        "            -0.351, -0.046, -0.503, 1.516, -0.692, -0.351, -0.88, -1.585,\n",
        "            -1.696, -0.275, -0.123, -0.389, -1.696, -0.767, 1.876, -0.123,\n",
        "            -0.692, 0.146, -0.275, 2.118\n",
        "        ],\n",
        "        'MW-Daltons': [\n",
        "            -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
        "            -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,\n",
        "            1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,\n",
        "            1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,\n",
        "            -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
        "            -1.0, -1.0, -1.0, -1.0\n",
        "        ],\n",
        "        'MW-kg': [\n",
        "            -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
        "            -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,\n",
        "            1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,\n",
        "            1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,\n",
        "            -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
        "            -1.0, -1.0, -1.0, -1.0\n",
        "        ],\n",
        "        'Nucleosome': [\n",
        "            -2.342, -0.555, 0.169, -2.004, 0.169, 0.266, 0.266, 0.459, -0.748,\n",
        "            1.28, 0.266, 0.459, -0.99, 0.217, 0.893, -2.004, -0.748, 0.797,\n",
        "            -0.314, 0.893, 0.266, 0.555, -0.072, 0.266, 1.666, 1.28, -0.072,\n",
        "            0.266, -1.28, 0.266, -0.314, 0.169, -0.893, 0.266, 0.266, 0.217,\n",
        "            0.555, 2.487, 1.28, 1.28, -0.507, 2.487, 0.555, 0.266, -0.555,\n",
        "            0.266, 0.797, -0.555, -1.376, -0.555, -1.28, -0.99, 0.266, -0.507,\n",
        "            1.666, -0.748, 0.266, 0.555, 0.266, 0.169, -1.376, -0.893, -0.748,\n",
        "            -2.342\n",
        "        ],\n",
        "        'Nucleosome-Rigid': [\n",
        "            2.386, 0.548, -0.179, 2.032, -0.179, -0.275, -0.275, -0.466, 0.743,\n",
        "            -1.272, -0.275, -0.466, 0.988, -0.227, -0.894, 2.032, 0.743, -0.8,\n",
        "            0.304, -0.894, -0.275, -0.562, 0.062, -0.275, -1.646, -1.272,\n",
        "            0.062, -0.275, 1.285, -0.275, 0.304, -0.179, 0.89, -0.275, -0.275,\n",
        "            -0.227, -0.562, -2.433, -1.272, -1.272, 0.499, -2.433, -0.562,\n",
        "            -0.275, 0.548, -0.275, -0.8, 0.548, 1.384, 0.548, 1.285, 0.988,\n",
        "            -0.275, 0.499, -1.646, 0.743, -0.275, -0.562, -0.275, -0.179,\n",
        "            1.384, 0.89, 0.743, 2.386\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    kmer_n = 3\n",
        "    return PCP(sequence, kmer_n, dna_property_dict)\n",
        "\n",
        "\n",
        "def MMI(sequence):\n",
        "    NN = 'ACGT'\n",
        "\n",
        "    nn_2_name = [''.join(sorted(item)) for item in itertools.product(NN, repeat=2)]\n",
        "    nn_3_name = [\n",
        "        ''.join(sorted(item)) for item in itertools.product(NN, repeat=3)\n",
        "    ]\n",
        "\n",
        "    nn_2_name = list(set(nn_2_name))\n",
        "    nn_3_name = list(set(nn_3_name))\n",
        "\n",
        "    nn_2_arr = KmerArray(sequence, 2, is_sort=True)\n",
        "    nn_3_arr = KmerArray(sequence, 3, is_sort=True)\n",
        "\n",
        "    # 统计\n",
        "    count_1 = Counter(sequence)\n",
        "    count_2 = Counter(nn_2_arr)\n",
        "    count_3 = Counter(nn_3_arr)\n",
        "\n",
        "    for nn, co in zip([NN, nn_2_name, nn_3_name], [count_1, count_2, count_3]):\n",
        "        for nn_ in nn:\n",
        "            if nn_ not in co:\n",
        "                co[nn_] = 0\n",
        "    # 归一\n",
        "    seq_len = len(sequence)\n",
        "    for idx, c_d in enumerate([count_1, count_2, count_3]):\n",
        "        for k in c_d.keys():\n",
        "            c_d[k] /= float(seq_len - idx)\n",
        "\n",
        "    # 计算\n",
        "    def val_1(k1, k2):\n",
        "        if (count_1[k1] * count_1[k2]) != 0 and count_2[k1 + k2] != 0:\n",
        "            return count_2[k1 + k2] * math.log(count_2[k1 + k2] / (count_1[k1] * count_1[k2]))\n",
        "\n",
        "        return 0\n",
        "\n",
        "    def val_2(k1, k2):\n",
        "        if count_2[k1 + k2] != 0 and count_1[k2] != 0:\n",
        "            return (count_2[k1 + k2] / count_1[k2]) * math.log(count_2[k1 + k2] / count_1[k2])\n",
        "\n",
        "        return 0\n",
        "\n",
        "    def val_3(k1, k2, k3):\n",
        "        if count_3[k1 + k2 + k3] != 0 and count_2[k2 + k3] != 0:\n",
        "            return (count_3[k1 + k2 + k3] / count_2[k2 + k3]) * math.log(count_3[k1 + k2 + k3] / count_2[k2 + k3])\n",
        "\n",
        "        return 0\n",
        "\n",
        "    res = []\n",
        "    for k in nn_2_name:\n",
        "        if k in count_2.keys():\n",
        "            res.append(val_1(k[0], k[1]))\n",
        "\n",
        "    for k in nn_3_name:\n",
        "        if k in count_3.keys():\n",
        "            res.append(val_1(k[0], k[1]) + val_2(k[0], k[2]) - val_3(k[0], k[1], k[2]))\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def Z_curve_9bit(sequence):\n",
        "    res = []\n",
        "    pos1_dict = {}\n",
        "    pos2_dict = {}\n",
        "    pos3_dict = {}\n",
        "    for i in range(len(sequence)):\n",
        "        if (i + 1) % 3 == 1:\n",
        "            if sequence[i] in pos1_dict:\n",
        "                pos1_dict[sequence[i]] += 1\n",
        "            else:\n",
        "                pos1_dict[sequence[i]] = 1\n",
        "        elif (i + 1) % 3 == 2:\n",
        "            if sequence[i] in pos2_dict:\n",
        "                pos2_dict[sequence[i]] += 1\n",
        "            else:\n",
        "                pos2_dict[sequence[i]] = 1\n",
        "        elif (i + 1) % 3 == 0:\n",
        "            if sequence[i] in pos3_dict:\n",
        "                pos3_dict[sequence[i]] += 1\n",
        "            else:\n",
        "                pos3_dict[sequence[i]] = 1\n",
        "\n",
        "    res += [(pos1_dict.get('A', 0) + pos1_dict.get('G', 0) -\n",
        "             pos1_dict.get('C', 0) - pos1_dict.get('T', 0)) / len(sequence),\n",
        "            (pos1_dict.get('A', 0) + pos1_dict.get('C', 0) -\n",
        "             pos1_dict.get('G', 0) - pos1_dict.get('T', 0)) / len(sequence),\n",
        "            (pos1_dict.get('A', 0) + pos1_dict.get('T', 0) -\n",
        "             pos1_dict.get('G', 0) - pos1_dict.get('C', 0)) / len(sequence)]\n",
        "    res += [(pos2_dict.get('A', 0) + pos2_dict.get('G', 0) -\n",
        "             pos2_dict.get('C', 0) - pos2_dict.get('T', 0)) / len(sequence),\n",
        "            (pos2_dict.get('A', 0) + pos2_dict.get('C', 0) -\n",
        "             pos2_dict.get('G', 0) - pos2_dict.get('T', 0)) / len(sequence),\n",
        "            (pos2_dict.get('A', 0) + pos2_dict.get('T', 0) -\n",
        "             pos2_dict.get('G', 0) - pos2_dict.get('C', 0)) / len(sequence)]\n",
        "    res += [(pos3_dict.get('A', 0) + pos3_dict.get('G', 0) -\n",
        "             pos3_dict.get('C', 0) - pos3_dict.get('T', 0)) / len(sequence),\n",
        "            (pos3_dict.get('A', 0) + pos3_dict.get('C', 0) -\n",
        "             pos3_dict.get('G', 0) - pos3_dict.get('T', 0)) / len(sequence),\n",
        "            (pos3_dict.get('A', 0) + pos3_dict.get('T', 0) -\n",
        "             pos3_dict.get('G', 0) - pos3_dict.get('C', 0)) / len(sequence)]\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def Z_curve_12bit(sequence):\n",
        "    res = []\n",
        "    pos_dict = {}\n",
        "    for i in range(len(sequence) - 1):\n",
        "        if sequence[i:i + 2] in pos_dict:\n",
        "            pos_dict[sequence[i:i + 2]] += 1\n",
        "        else:\n",
        "            pos_dict[sequence[i:i + 2]] = 1\n",
        "\n",
        "    NN = 'ACGT'\n",
        "    for base in NN:\n",
        "        res += [\n",
        "            (pos_dict.get('%sA' % base, 0) + pos_dict.get('%sG' % base, 0) -\n",
        "             pos_dict.get('%sC' % base, 0) - pos_dict.get('%sT' % base, 0)) /\n",
        "            (len(sequence) - 1),  # x\n",
        "            (pos_dict.get('%sA' % base, 0) + pos_dict.get('%sC' % base, 0) -\n",
        "             pos_dict.get('%sG' % base, 0) - pos_dict.get('%sT' % base, 0)) /\n",
        "            (len(sequence) - 1),  # y\n",
        "            (pos_dict.get('%sA' % base, 0) + pos_dict.get('%sT' % base, 0) -\n",
        "             pos_dict.get('%sG' % base, 0) - pos_dict.get('%sC' % base, 0)) /\n",
        "            (len(sequence) - 1)\n",
        "        ]\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def Z_curve_36bit(sequence):\n",
        "    res = []\n",
        "    pos1_dict = {}\n",
        "    pos2_dict = {}\n",
        "    pos3_dict = {}\n",
        "    for i in range(len(sequence) - 1):\n",
        "        if (i + 1) % 3 == 1:\n",
        "            if sequence[i:i + 2] in pos1_dict:\n",
        "                pos1_dict[sequence[i:i + 2]] += 1\n",
        "            else:\n",
        "                pos1_dict[sequence[i:i + 2]] = 1\n",
        "        elif (i + 1) % 3 == 2:\n",
        "            if sequence[i:i + 2] in pos2_dict:\n",
        "                pos2_dict[sequence[i:i + 2]] += 1\n",
        "            else:\n",
        "                pos2_dict[sequence[i:i + 2]] = 1\n",
        "        elif (i + 1) % 3 == 0:\n",
        "            if sequence[i:i + 2] in pos3_dict:\n",
        "                pos3_dict[sequence[i:i + 2]] += 1\n",
        "            else:\n",
        "                pos3_dict[sequence[i:i + 2]] = 1\n",
        "\n",
        "    NN = 'ACGT'\n",
        "    for base in NN:\n",
        "        res += [\n",
        "            (pos1_dict.get('%sA' % base, 0) + pos1_dict.get('%sG' % base, 0) -\n",
        "             pos1_dict.get('%sC' % base, 0) - pos1_dict.get('%sT' % base, 0)) /\n",
        "            (len(sequence) - 1),  # x\n",
        "            (pos1_dict.get('%sA' % base, 0) + pos1_dict.get('%sC' % base, 0) -\n",
        "             pos1_dict.get('%sG' % base, 0) - pos1_dict.get('%sT' % base, 0)) /\n",
        "            (len(sequence) - 1),  # y\n",
        "            (pos1_dict.get('%sA' % base, 0) + pos1_dict.get('%sT' % base, 0) -\n",
        "             pos1_dict.get('%sG' % base, 0) - pos1_dict.get('%sC' % base, 0)) /\n",
        "            (len(sequence) - 1)  # z\n",
        "        ]\n",
        "        res += [\n",
        "            (pos2_dict.get('%sA' % base, 0) + pos2_dict.get('%sG' % base, 0) -\n",
        "             pos2_dict.get('%sC' % base, 0) - pos2_dict.get('%sT' % base, 0)) /\n",
        "            (len(sequence) - 1),\n",
        "            (pos2_dict.get('%sA' % base, 0) + pos2_dict.get('%sC' % base, 0) -\n",
        "             pos2_dict.get('%sG' % base, 0) - pos2_dict.get('%sT' % base, 0)) /\n",
        "            (len(sequence) - 1),\n",
        "            (pos2_dict.get('%sA' % base, 0) + pos2_dict.get('%sT' % base, 0) -\n",
        "             pos2_dict.get('%sG' % base, 0) - pos2_dict.get('%sC' % base, 0)) /\n",
        "            (len(sequence) - 1)\n",
        "        ]\n",
        "        res += [\n",
        "            (pos3_dict.get('%sA' % base, 0) + pos3_dict.get('%sG' % base, 0) -\n",
        "             pos3_dict.get('%sC' % base, 0) - pos3_dict.get('%sT' % base, 0)) /\n",
        "            (len(sequence) - 1),\n",
        "            (pos3_dict.get('%sA' % base, 0) + pos3_dict.get('%sC' % base, 0) -\n",
        "             pos3_dict.get('%sG' % base, 0) - pos3_dict.get('%sT' % base, 0)) /\n",
        "            (len(sequence) - 1),\n",
        "            (pos3_dict.get('%sA' % base, 0) + pos3_dict.get('%sT' % base, 0) -\n",
        "             pos3_dict.get('%sG' % base, 0) - pos3_dict.get('%sC' % base, 0)) /\n",
        "            (len(sequence) - 1)\n",
        "        ]\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def Z_curve_48bit(sequence):\n",
        "    res = []\n",
        "    pos_dict = {}\n",
        "    for i in range(len(sequence) - 2):\n",
        "        if sequence[i:i + 3] in pos_dict:\n",
        "            pos_dict[sequence[i:i + 3]] += 1\n",
        "        else:\n",
        "            pos_dict[sequence[i:i + 3]] = 1\n",
        "\n",
        "    NN = 'ACGT'\n",
        "    for base in NN:\n",
        "        for base1 in NN:\n",
        "            res += [\n",
        "                (pos_dict.get('%s%sA' % (base, base1), 0) +\n",
        "                 pos_dict.get('%s%sG' % (base, base1), 0) - pos_dict.get(\n",
        "                     '%s%sC' %\n",
        "                     (base, base1), 0) - pos_dict.get('%s%sT' %\n",
        "                                                      (base, base1), 0)) /\n",
        "                (len(sequence) - 2),  # x\n",
        "                (pos_dict.get('%s%sA' % (base, base1), 0) + pos_dict.get(\n",
        "                    '%s%sC' %\n",
        "                    (base, base1), 0) - pos_dict.get('%s%sG' %\n",
        "                                                     (base, base1), 0) -\n",
        "                 pos_dict.get('%s%sT' %\n",
        "                              (base, base1), 0)) / (len(sequence) - 2),  # y\n",
        "                (pos_dict.get('%s%sA' % (base, base1), 0) + pos_dict.get(\n",
        "                    '%s%sT' %\n",
        "                    (base, base1), 0) - pos_dict.get('%s%sG' %\n",
        "                                                     (base, base1), 0) -\n",
        "                 pos_dict.get('%s%sC' %\n",
        "                              (base, base1), 0)) / (len(sequence) - 2)  # z\n",
        "            ]\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def Z_curve_144bit(sequence):\n",
        "    res = []\n",
        "    pos1_dict = {}\n",
        "    pos2_dict = {}\n",
        "    pos3_dict = {}\n",
        "    for i in range(len(sequence) - 2):\n",
        "        if (i + 1) % 3 == 1:\n",
        "            if sequence[i:i + 3] in pos1_dict:\n",
        "                pos1_dict[sequence[i:i + 3]] += 1\n",
        "            else:\n",
        "                pos1_dict[sequence[i:i + 3]] = 1\n",
        "        elif (i + 1) % 3 == 2:\n",
        "            if sequence[i:i + 3] in pos2_dict:\n",
        "                pos2_dict[sequence[i:i + 3]] += 1\n",
        "            else:\n",
        "                pos2_dict[sequence[i:i + 3]] = 1\n",
        "        elif (i + 1) % 3 == 0:\n",
        "            if sequence[i:i + 3] in pos3_dict:\n",
        "                pos3_dict[sequence[i:i + 3]] += 1\n",
        "            else:\n",
        "                pos3_dict[sequence[i:i + 3]] = 1\n",
        "\n",
        "    NN = 'ACGT'\n",
        "    for base in NN:\n",
        "        for base1 in NN:\n",
        "            res += [\n",
        "                (pos1_dict.get('%s%sA' % (base, base1), 0) +\n",
        "                 pos1_dict.get('%s%sG' % (base, base1), 0) - pos1_dict.get(\n",
        "                     '%s%sC' %\n",
        "                     (base, base1), 0) - pos1_dict.get('%s%sT' %\n",
        "                                                       (base, base1), 0)) /\n",
        "                (len(sequence) - 2),  # x\n",
        "                (pos1_dict.get('%s%sA' % (base, base1), 0) + pos1_dict.get(\n",
        "                    '%s%sC' %\n",
        "                    (base, base1), 0) - pos1_dict.get('%s%sG' %\n",
        "                                                      (base, base1), 0) -\n",
        "                 pos1_dict.get('%s%sT' %\n",
        "                               (base, base1), 0)) / (len(sequence) - 2),  # y\n",
        "                (pos1_dict.get('%s%sA' % (base, base1), 0) + pos1_dict.get(\n",
        "                    '%s%sT' %\n",
        "                    (base, base1), 0) - pos1_dict.get('%s%sG' %\n",
        "                                                      (base, base1), 0) -\n",
        "                 pos1_dict.get('%s%sC' %\n",
        "                               (base, base1), 0)) / (len(sequence) - 2)  # z\n",
        "            ]\n",
        "            res += [\n",
        "                (pos2_dict.get('%s%sA' % (base, base1), 0) +\n",
        "                 pos2_dict.get('%s%sG' % (base, base1), 0) - pos2_dict.get(\n",
        "                     '%s%sC' %\n",
        "                     (base, base1), 0) - pos2_dict.get('%s%sT' %\n",
        "                                                       (base, base1), 0)) /\n",
        "                (len(sequence) - 2),  # x\n",
        "                (pos2_dict.get('%s%sA' % (base, base1), 0) + pos2_dict.get(\n",
        "                    '%s%sC' %\n",
        "                    (base, base1), 0) - pos2_dict.get('%s%sG' %\n",
        "                                                      (base, base1), 0) -\n",
        "                 pos2_dict.get('%s%sT' %\n",
        "                               (base, base1), 0)) / (len(sequence) - 2),  # y\n",
        "                (pos2_dict.get('%s%sA' % (base, base1), 0) + pos2_dict.get(\n",
        "                    '%s%sT' %\n",
        "                    (base, base1), 0) - pos2_dict.get('%s%sG' %\n",
        "                                                      (base, base1), 0) -\n",
        "                 pos2_dict.get('%s%sC' %\n",
        "                               (base, base1), 0)) / (len(sequence) - 2)  # z\n",
        "            ]\n",
        "            res += [\n",
        "                (pos3_dict.get('%s%sA' % (base, base1), 0) +\n",
        "                 pos3_dict.get('%s%sG' % (base, base1), 0) - pos3_dict.get(\n",
        "                     '%s%sC' %\n",
        "                     (base, base1), 0) - pos3_dict.get('%s%sT' %\n",
        "                                                       (base, base1), 0)) /\n",
        "                (len(sequence) - 2),  # x\n",
        "                (pos3_dict.get('%s%sA' % (base, base1), 0) + pos3_dict.get(\n",
        "                    '%s%sC' %\n",
        "                    (base, base1), 0) - pos3_dict.get('%s%sG' %\n",
        "                                                      (base, base1), 0) -\n",
        "                 pos3_dict.get('%s%sT' %\n",
        "                               (base, base1), 0)) / (len(sequence) - 2),  # y\n",
        "                (pos3_dict.get('%s%sA' % (base, base1), 0) + pos3_dict.get(\n",
        "                    '%s%sT' %\n",
        "                    (base, base1), 0) - pos3_dict.get('%s%sG' %\n",
        "                                                      (base, base1), 0) -\n",
        "                 pos3_dict.get('%s%sC' %\n",
        "                               (base, base1), 0)) / (len(sequence) - 2)  # z\n",
        "            ]\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def PseDNC(sequence):\n",
        "    lamada_val = 3\n",
        "    weight = 0.05\n",
        "\n",
        "    kmer_n = 2\n",
        "\n",
        "    property_name = ['Twist', 'Tilt', 'Roll', 'Shift', 'Slide', 'Rise']\n",
        "    property_value = {\n",
        "        'Twist': [\n",
        "            0.063, 1.502, 0.783, 1.071, -1.376, 0.063, -1.664, 0.783, -0.081,\n",
        "            -0.081, 0.063, 1.502, -1.233, -0.081, -1.376, 0.063\n",
        "        ],\n",
        "        'Tilt': [\n",
        "            0.502, 0.502, 0.359, 0.215, -1.364, 1.077, -1.22, 0.359, 0.502,\n",
        "            0.215, 1.077, 0.502, -2.368, 0.502, -1.364, 0.502\n",
        "        ],\n",
        "        'Roll': [\n",
        "            0.09, 1.19, -0.28, 0.83, -1.01, -0.28, -1.38, -0.28, 0.09, 2.3,\n",
        "            -0.28, 1.19, -1.38, 0.09, -1.01, 0.09\n",
        "        ],\n",
        "        'Shift': [\n",
        "            1.587, 0.126, 0.679, -1.019, -0.861, 0.56, -0.822, 0.679, 0.126,\n",
        "            -0.348, 0.56, 0.126, -2.243, 0.126, -0.861, 1.587\n",
        "        ],\n",
        "        'Slide': [\n",
        "            0.111, 1.289, -0.241, 2.513, -0.623, -0.822, -0.287, -0.241,\n",
        "            -0.394, 0.646, -0.822, 1.289, -1.511, -0.394, -0.623, 0.111\n",
        "        ],\n",
        "        'Rise': [\n",
        "            -0.109, 1.044, -0.623, 1.171, -1.254, 0.242, -1.389, -0.623, 0.711,\n",
        "            1.585, 0.242, 1.044, -1.389, 0.711, -1.254, -0.109\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    NN = 'ACGT'\n",
        "    nn_name = [''.join(item) for item in itertools.product(NN, repeat=kmer_n)]\n",
        "\n",
        "    nn_arr = KmerArray(sequence, kmer_n)\n",
        "    count = Counter(nn_arr)\n",
        "\n",
        "    for k in count:\n",
        "        count[k] /= len(sequence) - kmer_n + 1\n",
        "\n",
        "    theta_arr = []\n",
        "    for tmp_lamada in range(lamada_val):\n",
        "        theta = 0\n",
        "        for i in range(len(sequence) - tmp_lamada - kmer_n):\n",
        "            kk = 0\n",
        "            for p_name in property_name:\n",
        "                kk += (property_value[p_name][nn_name.index(\n",
        "                    sequence[i:i + kmer_n])] -\n",
        "                       property_value[p_name][nn_name.index(\n",
        "                           sequence[i + tmp_lamada + 1:i + tmp_lamada + 1 +\n",
        "                                    kmer_n])])**2\n",
        "\n",
        "            theta += kk / len(property_name)\n",
        "        theta_arr.append(theta / (len(sequence) - tmp_lamada - kmer_n))\n",
        "\n",
        "    res = []\n",
        "    for k in nn_name:\n",
        "        res.append(count[k] / (1 + weight * sum(theta_arr)))\n",
        "\n",
        "    start_i = len(NN)**kmer_n + 1\n",
        "    for k in range(start_i, start_i + lamada_val):\n",
        "        res.append(\n",
        "            (weight * theta_arr[k - start_i]) / (1 + weight * sum(theta_arr)))\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def PseKNC(sequence):\n",
        "    \"\"\"\n",
        "    return 1 x 66\n",
        "    \"\"\"\n",
        "    lamada_val = 2\n",
        "    weight = 0.1\n",
        "\n",
        "    kmer_n = 3\n",
        "\n",
        "    property_name = ['Twist', 'Tilt', 'Roll', 'Shift', 'Slide', 'Rise']\n",
        "    property_value = {\n",
        "        'Twist': [\n",
        "            0.063, 1.502, 0.783, 1.071, -1.376, 0.063, -1.664, 0.783, -0.081,\n",
        "            -0.081, 0.063, 1.502, -1.233, -0.081, -1.376, 0.063\n",
        "        ],\n",
        "        'Tilt': [\n",
        "            0.502, 0.502, 0.359, 0.215, -1.364, 1.077, -1.22, 0.359, 0.502,\n",
        "            0.215, 1.077, 0.502, -2.368, 0.502, -1.364, 0.502\n",
        "        ],\n",
        "        'Roll': [\n",
        "            0.09, 1.19, -0.28, 0.83, -1.01, -0.28, -1.38, -0.28, 0.09, 2.3,\n",
        "            -0.28, 1.19, -1.38, 0.09, -1.01, 0.09\n",
        "        ],\n",
        "        'Shift': [\n",
        "            1.587, 0.126, 0.679, -1.019, -0.861, 0.56, -0.822, 0.679, 0.126,\n",
        "            -0.348, 0.56, 0.126, -2.243, 0.126, -0.861, 1.587\n",
        "        ],\n",
        "        'Slide': [\n",
        "            0.111, 1.289, -0.241, 2.513, -0.623, -0.822, -0.287, -0.241,\n",
        "            -0.394, 0.646, -0.822, 1.289, -1.511, -0.394, -0.623, 0.111\n",
        "        ],\n",
        "        'Rise': [\n",
        "            -0.109, 1.044, -0.623, 1.171, -1.254, 0.242, -1.389, -0.623, 0.711,\n",
        "            1.585, 0.242, 1.044, -1.389, 0.711, -1.254, -0.109\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    NN = 'ACGT'\n",
        "    nn_2_name = [''.join(item) for item in itertools.product(NN, repeat=2)]\n",
        "    nn_3_name = [\n",
        "        ''.join(item) for item in itertools.product(NN, repeat=kmer_n)\n",
        "    ]\n",
        "\n",
        "    nn_3_arr = KmerArray(sequence, kmer_n)\n",
        "    count_3 = Counter(nn_3_arr)\n",
        "\n",
        "    for k in count_3:\n",
        "        count_3[k] /= len(sequence) - kmer_n + 1\n",
        "\n",
        "    theta_arr = []\n",
        "    kmer_n_ = 2\n",
        "    for tmp_lamada in range(lamada_val):\n",
        "        theta = 0\n",
        "        for i in range(len(sequence) - tmp_lamada - kmer_n_):\n",
        "            kk = 0\n",
        "            for p_name in property_name:\n",
        "                kk += (property_value[p_name][nn_2_name.index(\n",
        "                    sequence[i:i + kmer_n_])] -\n",
        "                       property_value[p_name][nn_2_name.index(\n",
        "                           sequence[i + tmp_lamada + 1:i + tmp_lamada + 1 +\n",
        "                                    kmer_n_])])**2\n",
        "\n",
        "            theta += kk / len(property_name)\n",
        "        theta_arr.append(theta / (len(sequence) - tmp_lamada - kmer_n_))\n",
        "\n",
        "    res = []\n",
        "    for k in nn_3_name:\n",
        "        res.append(count_3[k] / (1 + weight * sum(theta_arr)))\n",
        "\n",
        "    start_i = len(NN)**kmer_n + 1\n",
        "    for k in range(start_i, start_i + lamada_val):\n",
        "        res.append(\n",
        "            (weight * theta_arr[k - start_i]) / (1 + weight * sum(theta_arr)))\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def PCPseTNC(sequence):\n",
        "    lamada_val = 3\n",
        "    weight = 0.05\n",
        "\n",
        "    kmer_n = 3\n",
        "\n",
        "    property_name = ['Dnase I', 'Bendability (DNAse)']\n",
        "    property_value = {\n",
        "        'Dnase I': [\n",
        "            2.274, 1.105, 0.193, 2.141, -0.153, -0.078, -0.074, 0.536, 0.109,\n",
        "            -0.753, 0.039, 0.536, -0.491, 0.307, -1.112, 2.141, 0.166, -0.646,\n",
        "            -0.762, -1.112, 0.917, -0.3, 0.558, 0.039, -0.834, -0.326, 0.558,\n",
        "            -0.074, 0.062, -0.365, -0.762, 0.193, 0.474, -0.165, -0.365, 0.307,\n",
        "            -0.702, -1.687, -0.326, -0.753, 0.066, -1.687, -0.3, -0.078, 0.031,\n",
        "            -0.165, -0.646, 1.105, 0.206, 0.031, 0.062, -0.491, -1.103, 0.066,\n",
        "            -0.834, 0.109, 4.522, -0.702, 0.917, -0.153, 0.206, 0.474, 0.166,\n",
        "            -2.615\n",
        "        ],\n",
        "        'Bendability (DNAse)': [\n",
        "            -2.087, -1.509, -0.506, -2.126, 0.111, -0.121, -0.121, -1.354,\n",
        "            0.381, 0.304, -0.313, -1.354, 1.615, -0.737, 1.229, -2.126, 0.265,\n",
        "            0.496, 1.576, 1.229, -1.856, 0.072, -0.969, -0.313, 0.111, -0.468,\n",
        "            -0.969, -0.121, 0.882, 0.419, 1.576, -0.506, -0.159, 0.034, 0.419,\n",
        "            -0.737, 0.766, 1.036, -0.468, 0.304, 0.265, 1.036, 0.072, -0.121,\n",
        "            0.342, 0.034, 0.496, -1.509, 0.689, 0.342, 0.882, 1.615, 1.73,\n",
        "            0.265, 0.111, 0.381, 1.73, 0.766, -1.856, 0.111, 0.689, -0.159,\n",
        "            0.265, -2.087\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    NN = 'ACGT'\n",
        "    nn_name = [''.join(item) for item in itertools.product(NN, repeat=kmer_n)]\n",
        "\n",
        "    nn_arr = KmerArray(sequence, kmer_n)\n",
        "    count = Counter(nn_arr)\n",
        "\n",
        "    for k in count:\n",
        "        count[k] /= len(sequence) - kmer_n + 1\n",
        "\n",
        "    theta_arr = []\n",
        "    kmer_n_ = kmer_n\n",
        "    for tmp_lamada in range(lamada_val):\n",
        "        theta = 0\n",
        "        for i in range(len(sequence) - tmp_lamada - kmer_n_):\n",
        "            kk = 0\n",
        "            for p_name in property_name:\n",
        "                kk += (property_value[p_name][nn_name.index(\n",
        "                    sequence[i:i + kmer_n_])] -\n",
        "                       property_value[p_name][nn_name.index(\n",
        "                           sequence[i + tmp_lamada + 1:i + tmp_lamada + 1 +\n",
        "                                    kmer_n_])])**2\n",
        "\n",
        "            theta += kk / len(property_name)\n",
        "        theta_arr.append(theta / (len(sequence) - tmp_lamada - kmer_n_))\n",
        "\n",
        "    res = []\n",
        "    for k in nn_name:\n",
        "        res.append(count[k] / (1 + weight * sum(theta_arr)))\n",
        "\n",
        "    start_i = len(NN)**kmer_n + 1\n",
        "    for k in range(start_i, start_i + lamada_val):\n",
        "        res.append(\n",
        "            (weight * theta_arr[k - start_i]) / (1 + weight * sum(theta_arr)))\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def SCPseDNC(sequence):\n",
        "    \"\"\"\n",
        "    return 1 x 34\n",
        "    \"\"\"\n",
        "    lamada_val = 3\n",
        "    weight = 0.05\n",
        "\n",
        "    kmer_n = 2\n",
        "\n",
        "    property_name = ['Twist', 'Tilt', 'Roll', 'Shift', 'Slide', 'Rise']\n",
        "    property_value = {\n",
        "        'Twist': [\n",
        "            0.063, 1.502, 0.783, 1.071, -1.376, 0.063, -1.664, 0.783, -0.081,\n",
        "            -0.081, 0.063, 1.502, -1.233, -0.081, -1.376, 0.063\n",
        "        ],\n",
        "        'Tilt': [\n",
        "            0.502, 0.502, 0.359, 0.215, -1.364, 1.077, -1.22, 0.359, 0.502,\n",
        "            0.215, 1.077, 0.502, -2.368, 0.502, -1.364, 0.502\n",
        "        ],\n",
        "        'Roll': [\n",
        "            0.09, 1.19, -0.28, 0.83, -1.01, -0.28, -1.38, -0.28, 0.09, 2.3,\n",
        "            -0.28, 1.19, -1.38, 0.09, -1.01, 0.09\n",
        "        ],\n",
        "        'Shift': [\n",
        "            1.587, 0.126, 0.679, -1.019, -0.861, 0.56, -0.822, 0.679, 0.126,\n",
        "            -0.348, 0.56, 0.126, -2.243, 0.126, -0.861, 1.587\n",
        "        ],\n",
        "        'Slide': [\n",
        "            0.111, 1.289, -0.241, 2.513, -0.623, -0.822, -0.287, -0.241,\n",
        "            -0.394, 0.646, -0.822, 1.289, -1.511, -0.394, -0.623, 0.111\n",
        "        ],\n",
        "        'Rise': [\n",
        "            -0.109, 1.044, -0.623, 1.171, -1.254, 0.242, -1.389, -0.623, 0.711,\n",
        "            1.585, 0.242, 1.044, -1.389, 0.711, -1.254, -0.109\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    NN = 'ACGT'\n",
        "    nn_name = [''.join(item) for item in itertools.product(NN, repeat=kmer_n)]\n",
        "\n",
        "    nn_arr = KmerArray(sequence, kmer_n)\n",
        "    count = Counter(nn_arr)\n",
        "\n",
        "    for k in count:\n",
        "        count[k] /= len(sequence) - kmer_n + 1\n",
        "\n",
        "    theta_arr = []\n",
        "    kmer_n_ = kmer_n\n",
        "    for tmp_lamada in range(lamada_val):\n",
        "        for p_name in property_name:\n",
        "            theta = 0\n",
        "            for i in range(len(sequence) - tmp_lamada - kmer_n_):\n",
        "                theta += (property_value[p_name][nn_name.index(\n",
        "                    sequence[i:i + kmer_n_])] *\n",
        "                          property_value[p_name][nn_name.index(\n",
        "                              sequence[i + tmp_lamada + 1:i + tmp_lamada + 1 +\n",
        "                                       kmer_n_])])\n",
        "\n",
        "            theta_arr.append(theta / (len(sequence) - tmp_lamada - kmer_n_))\n",
        "\n",
        "    res = []\n",
        "    for k in nn_name:\n",
        "        res.append(count[k] / (1 + weight * sum(theta_arr)))\n",
        "\n",
        "    start_i = len(NN)**kmer_n + 1\n",
        "    for k in range(start_i, start_i + lamada_val * len(property_name)):\n",
        "        res.append(\n",
        "            (weight * theta_arr[k - start_i]) / (1 + weight * sum(theta_arr)))\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def SCPseTNC(sequence):\n",
        "    lamada_val = 3\n",
        "    weight = 0.05\n",
        "\n",
        "    kmer_n = 3\n",
        "\n",
        "    property_name = ['Dnase I', 'Bendability (DNAse)']\n",
        "    property_value = {\n",
        "        'Dnase I': [\n",
        "            2.274, 1.105, 0.193, 2.141, -0.153, -0.078, -0.074, 0.536, 0.109,\n",
        "            -0.753, 0.039, 0.536, -0.491, 0.307, -1.112, 2.141, 0.166, -0.646,\n",
        "            -0.762, -1.112, 0.917, -0.3, 0.558, 0.039, -0.834, -0.326, 0.558,\n",
        "            -0.074, 0.062, -0.365, -0.762, 0.193, 0.474, -0.165, -0.365, 0.307,\n",
        "            -0.702, -1.687, -0.326, -0.753, 0.066, -1.687, -0.3, -0.078, 0.031,\n",
        "            -0.165, -0.646, 1.105, 0.206, 0.031, 0.062, -0.491, -1.103, 0.066,\n",
        "            -0.834, 0.109, 4.522, -0.702, 0.917, -0.153, 0.206, 0.474, 0.166,\n",
        "            -2.615\n",
        "        ],\n",
        "        'Bendability (DNAse)': [\n",
        "            -2.087, -1.509, -0.506, -2.126, 0.111, -0.121, -0.121, -1.354,\n",
        "            0.381, 0.304, -0.313, -1.354, 1.615, -0.737, 1.229, -2.126, 0.265,\n",
        "            0.496, 1.576, 1.229, -1.856, 0.072, -0.969, -0.313, 0.111, -0.468,\n",
        "            -0.969, -0.121, 0.882, 0.419, 1.576, -0.506, -0.159, 0.034, 0.419,\n",
        "            -0.737, 0.766, 1.036, -0.468, 0.304, 0.265, 1.036, 0.072, -0.121,\n",
        "            0.342, 0.034, 0.496, -1.509, 0.689, 0.342, 0.882, 1.615, 1.73,\n",
        "            0.265, 0.111, 0.381, 1.73, 0.766, -1.856, 0.111, 0.689, -0.159,\n",
        "            0.265, -2.087\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    NN = 'ACGT'\n",
        "    nn_name = [''.join(item) for item in itertools.product(NN, repeat=kmer_n)]\n",
        "\n",
        "    nn_arr = KmerArray(sequence, kmer_n)\n",
        "    count = Counter(nn_arr)\n",
        "\n",
        "    for k in count:\n",
        "        count[k] /= len(sequence) - kmer_n + 1\n",
        "\n",
        "    theta_arr = []\n",
        "    kmer_n_ = kmer_n\n",
        "    for tmp_lamada in range(lamada_val):\n",
        "        for p_name in property_name:\n",
        "            theta = 0\n",
        "            for i in range(len(sequence) - tmp_lamada - kmer_n_):\n",
        "                theta += (property_value[p_name][nn_name.index(\n",
        "                    sequence[i:i + kmer_n_])] *\n",
        "                          property_value[p_name][nn_name.index(\n",
        "                              sequence[i + tmp_lamada + 1:i + tmp_lamada + 1 +\n",
        "                                       kmer_n_])])\n",
        "\n",
        "            theta_arr.append(theta / (len(sequence) - tmp_lamada - kmer_n_))\n",
        "\n",
        "    res = []\n",
        "    for k in nn_name:\n",
        "        res.append(count[k] / (1 + weight * sum(theta_arr)))\n",
        "\n",
        "    start_i = len(NN)**kmer_n + 1\n",
        "    for k in range(start_i, start_i + lamada_val * len(property_name)):\n",
        "        res.append(\n",
        "            (weight * theta_arr[k - start_i]) / (1 + weight * sum(theta_arr)))\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "class DNAFeature:\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        18 DNA characterization methods\n",
        "        \"\"\"\n",
        "        self.embedding_func = {\n",
        "            'Kmer': Kmer,\n",
        "            'RCKmer': RCKmer,\n",
        "            'Mismatch': Mismatch,\n",
        "            'CKSNAP': CKSNAP,\n",
        "            'PseEIIP': PseEIIP,\n",
        "            'DPCP': DPCP,\n",
        "            'TPCP': TPCP,\n",
        "            'MMI': MMI,\n",
        "            'Z_curve_9bit': Z_curve_9bit,\n",
        "            'Z_curve_12bit': Z_curve_12bit,\n",
        "            'Z_curve_36bit': Z_curve_36bit,\n",
        "            'Z_curve_48bit': Z_curve_48bit,\n",
        "            'Z_curve_144bit': Z_curve_144bit,\n",
        "            'PseDNC': PseDNC,\n",
        "            'PseKNC': PseKNC,\n",
        "            'PCPseTNC': PCPseTNC,\n",
        "            'SCPseDNC': SCPseDNC,\n",
        "            'SCPseTNC': SCPseTNC\n",
        "        }\n",
        "        print(f'Info: {len(self.embedding_func)} DNA characterization methods')\n",
        "\n",
        "    def get_embedding_type(self):\n",
        "        return list(self.embedding_func.keys())\n",
        "\n",
        "    def display_example(self):\n",
        "        seq = 'ATGGCAACGTCATGGTGCCGGGATTTTTGGCAGGCTTTTCGCCCTGGGATCCTACCGGGCAGCTTCCGAGGTGAGCTGGAAACCTTCCGTAAACTCGTCGAGCGCGACGCGCCGAGACGGGGCCTCGAGCACCACCACCACCACCACTGA'\n",
        "\n",
        "        embedding_size = 0\n",
        "        for i, embedding_name in enumerate(self.embedding_func.keys(), start=1):\n",
        "            embedding = self.embedding_func[embedding_name](seq)\n",
        "            embedding_size += len(embedding)\n",
        "\n",
        "            print(f'{i}-{embedding_name}: {len(embedding)}')\n",
        "\n",
        "        print('embedding_size', embedding_size, embedding_size - 768)\n",
        "\n",
        "    def get_embedding(self, seq, feature_name):\n",
        "        if feature_name not in self.embedding_func.keys():\n",
        "            raise ValueError(f'No {feature_name} embedding type.')\n",
        "\n",
        "        assert set('ACGT') == set(seq)\n",
        "\n",
        "        return self.embedding_func[feature_name](seq)\n",
        "\n",
        "    def init_feature_fit(self, seqs, embedding_fit_file):\n",
        "        if os.path.exists(embedding_fit_file):\n",
        "            # 控制更新某个\n",
        "            with open(embedding_fit_file, 'rb') as w:\n",
        "                embedding_fit = pickle.load(w)\n",
        "        else:\n",
        "            embedding_fit = {}\n",
        "\n",
        "        for i, embedding_name in enumerate(self.embedding_func.keys(), start=1):\n",
        "#             if embedding_name not in ['TPCP']:\n",
        "#                 continue\n",
        "\n",
        "            pbar = tqdm(total=len(seqs), desc=f'{i}-{embedding_name}')\n",
        "\n",
        "            embeddings = []\n",
        "            for seq in seqs:\n",
        "                embeddings.append(self.embedding_func[embedding_name](seq))\n",
        "\n",
        "                pbar.update(1)\n",
        "\n",
        "            pbar.close()\n",
        "\n",
        "            # 降维\n",
        "            if embedding_name == 'TPCP':\n",
        "                pca = PCA(n_components=105)\n",
        "                embeddings = pca.fit_transform(embeddings)\n",
        "\n",
        "                embedding_fit[f'{embedding_name} PCA'] = pca\n",
        "\n",
        "            scaler = MinMaxScaler()\n",
        "            scaler.fit(embeddings)\n",
        "\n",
        "            embedding_fit[f'{embedding_name} Scaler'] = scaler\n",
        "\n",
        "        with open(embedding_fit_file, 'wb') as w:\n",
        "            pickle.dump(embedding_fit, w)\n",
        "\n",
        "        print(\n",
        "            f'Info: wtire scaler and pca ({len(embedding_fit)}) to {embedding_fit_file}'\n",
        "        )\n",
        "\n",
        "    def exec_seqs_embedding(self, seqs, names, embedding_fit_file,\n",
        "                            embedding_res_file):\n",
        "        with open(embedding_fit_file, 'rb') as w:\n",
        "            embedding_fit = pickle.load(w)\n",
        "\n",
        "        pbar = tqdm(total=len(seqs))\n",
        "\n",
        "        seq_embeddings = {}\n",
        "        for name, seq in zip(names, seqs):\n",
        "            embeddings = []\n",
        "            for embedding_name in self.embedding_func.keys():\n",
        "                embedding = self.embedding_func[embedding_name](seq)\n",
        "\n",
        "                if embedding_name == 'TPCP':\n",
        "                    embedding = embedding_fit[\n",
        "                        f'{embedding_name} PCA'].transform([embedding])\n",
        "\n",
        "                    embedding = embedding_fit[\n",
        "                        f'{embedding_name} Scaler'].transform(embedding)\n",
        "                else:\n",
        "                    embedding = embedding_fit[\n",
        "                        f'{embedding_name} Scaler'].transform([embedding])\n",
        "\n",
        "                # MinMaxScale 数值舍入误差导致的 会有负数\n",
        "                embedding[embedding < 0] = 0\n",
        "\n",
        "                embeddings += list(embedding[0])\n",
        "\n",
        "            seq_embeddings[name] = {'embedding': embeddings}\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "        pbar.close()\n",
        "\n",
        "        with open(embedding_res_file, 'wb') as w:\n",
        "            pickle.dump(seq_embeddings, w)\n",
        "\n",
        "        print(\n",
        "            f'Info: feature embedding finish. num is ({len(seq_embeddings)}) to {embedding_res_file}'\n",
        "        )\n",
        "\n",
        "# df = DNAFeature()\n",
        "# et = df.get_embedding_type()\n",
        "# df.display_example()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "93e12974",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.477003Z",
          "start_time": "2024-06-18T13:46:11.472583Z"
        },
        "code_folding": [
          0
        ],
        "id": "93e12974"
      },
      "outputs": [],
      "source": [
        "def Fearture_embedding(dna_seq_csv, save_embedding_res_file):\n",
        "    feature = DNAFeature()\n",
        "\n",
        "    with open(dna_seq_csv, 'r', encoding='utf-8') as r:\n",
        "            data = list(csv.reader(r))[1:]\n",
        "\n",
        "    data = np.array(data)\n",
        "    names = list(data[:, 0])\n",
        "    seqs = list(data[:, 1])\n",
        "\n",
        "    embedding_fit_file = f'{resource_dir}/feature-embedding-fit.pickle'\n",
        "\n",
        "    feature.exec_seqs_embedding(seqs, names, embedding_fit_file, save_embedding_res_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f7e6c7ae",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.481755Z",
          "start_time": "2024-06-18T13:46:11.477929Z"
        },
        "code_folding": [],
        "id": "f7e6c7ae",
        "outputId": "90b95cfe-14d0-42f1-b149-0e1bc1af07b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "5e4dc56cab5249aca4f45695c07da743",
            "39e15caf31e642dd85c4f6431850d100",
            "f10a959c3bbc4e929594e62e274496a3",
            "09289f15d4a1425f9d7c34d05c3bc07a",
            "76c5e4202d514d9e9dbd04206117a072",
            "75f0a457195c41bea5de9c70db00cc69",
            "4181084e467f488397ef7cf0c7b7ff73",
            "5d5b69e94ebb4bfeb4ed386580604f6d",
            "b140b08930c3490d88e8add8af016516",
            "c14622011fe842c5bd138e4b99bf7bd8",
            "1e53510b76b54fd6b7719179180ea6a7"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Info: 18 DNA characterization methods\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.3.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.3.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e4dc56cab5249aca4f45695c07da743"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Info: feature embedding finish. num is (8) to scg-gelp-res/SSS_scg_dnas_feature_embedding_test.pickle\n"
          ]
        }
      ],
      "source": [
        "if is_test:\n",
        "    dna_file = f'{res_dir}/{protein_name}_scg_dnas_test.csv'\n",
        "\n",
        "    # Feature engineering code  Result file\n",
        "    dna_feature_embedding_pickle = f'{res_dir}/{protein_name}_scg_dnas_feature_embedding_test.pickle'\n",
        "\n",
        "    Fearture_embedding(dna_file, dna_feature_embedding_pickle)\n",
        "\n",
        "#     raise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0372ece",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-17T07:06:37.590870Z",
          "start_time": "2024-06-17T07:06:37.589147Z"
        },
        "id": "a0372ece"
      },
      "source": [
        "### Transfer learning (DNABER-2) feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "36762778",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.501328Z",
          "start_time": "2024-06-18T13:46:11.482716Z"
        },
        "code_folding": [
          0
        ],
        "id": "36762778"
      },
      "outputs": [],
      "source": [
        "class SeqenceDataset(Dataset):\n",
        "    def __init__(self, data_file: str):\n",
        "\n",
        "        super(SeqenceDataset, self).__init__()\n",
        "\n",
        "        # load data from the disk\n",
        "        with open(data_file, \"r\") as f:\n",
        "            data = list(csv.reader(f))[1:]\n",
        "\n",
        "        self.names = [d[0] for d in data]\n",
        "        self.labels = [d[2] for d in data]\n",
        "        self.texts = [d[1] for d in data]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.names[i], self.texts[i], self.labels[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "215ede3a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.525190Z",
          "start_time": "2024-06-18T13:46:11.502246Z"
        },
        "code_folding": [
          0
        ],
        "id": "215ede3a"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch_samples, tokenizer):\n",
        "    batch_names = []\n",
        "    batch_texts = []\n",
        "    batch_labels = []\n",
        "\n",
        "    for sample in batch_samples:\n",
        "        batch_names.append(sample[0])\n",
        "        batch_texts.append(sample[1])\n",
        "        batch_labels.append(int(sample[2]))\n",
        "\n",
        "    # return_attention_mask：是否返回 attention mask。Attention mask 用于表示哪些位置在文本中是有效的，哪些是 padding\n",
        "    #return_token_type_ids：是否返回 token type ids。Token type ids 用于区分文本中不同句子的标识\n",
        "    X = tokenizer(\n",
        "        batch_texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "        return_attention_mask=True,\n",
        "        return_token_type_ids=False\n",
        "    )\n",
        "\n",
        "    y = batch_labels\n",
        "\n",
        "    return batch_names, X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7740d1a1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.533697Z",
          "start_time": "2024-06-18T13:46:11.526211Z"
        },
        "code_folding": [
          0
        ],
        "id": "7740d1a1"
      },
      "outputs": [],
      "source": [
        "#\n",
        "from tqdm.auto import tqdm\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# embedding\n",
        "def dnabert_embedding(model, dataloader, scaler, embedding_data_file, device):\n",
        "    gene_name_info, embedding_res_info, label_info = [], [], []\n",
        "\n",
        "    embedding_data = {}\n",
        "\n",
        "    bar = tqdm(total=len(dataloader))\n",
        "\n",
        "    all_embedding = []\n",
        "    for gene_names, batch_X, labels in dataloader:\n",
        "        bar.update(1)\n",
        "\n",
        "        # get input and batch_len\n",
        "        batch_lens = [attention_mask.sum().item() for attention_mask in batch_X['attention_mask']]\n",
        "        inputs = batch_X['input_ids'].to(device)\n",
        "        print(batch_lens)\n",
        "\n",
        "        print(inputs.shape)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            hidden_states = model(inputs)[0]\n",
        "\n",
        "        # Generate per-sequence representations via averaging\n",
        "#             batch_representations = []\n",
        "        for i, seq_len in enumerate(batch_lens):\n",
        "            representations_tensor = hidden_states[i, 1: seq_len-1].mean(0).cpu().numpy()\n",
        "#                 batch_representations.append(representations_tensor.cpu().numpy())\n",
        "            embedding_data[gene_names[i]] = {'embedding': representations_tensor, 'label': labels[i]}\n",
        "\n",
        "            all_embedding.append(representations_tensor)\n",
        "\n",
        "#             batch_representations = torch.stack(batch_representations, dim=0)\n",
        "\n",
        "#             for index, gene_name in enumerate(gene_names):\n",
        "#                 gene_name_info.append(gene_name)\n",
        "#                 embedding_res_info.append(batch_representations[index])\n",
        "#                 label_info.append(labels[index])\n",
        "\n",
        "#         embedding_data = {'gene-name': gene_name_info, 'embedding': embedding_res_info, 'label': np.array(label_info)}\n",
        "\n",
        "#         embedding_data_file = f'data/{tag}_dnabert_embedding.pkl'\n",
        "\n",
        "    # fit\n",
        "    for k in embedding_data:\n",
        "        embedding_data[k]['embedding'] = scaler.transform([embedding_data[k]['embedding']])[0]\n",
        "\n",
        "    with open(embedding_data_file, 'wb') as w:\n",
        "        pickle.dump(embedding_data, w)\n",
        "\n",
        "    bar.close()\n",
        "\n",
        "    return embedding_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "3a539522",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.538852Z",
          "start_time": "2024-06-18T13:46:11.534738Z"
        },
        "code_folding": [],
        "id": "3a539522"
      },
      "outputs": [],
      "source": [
        "def DNABERT_2_Embedding_Func(dna_file, dna_dnabert_embedding_pickle):\n",
        "    # tokenizer and dnabert-2 model\n",
        "    # checkpoint = f'{resource_dir}/DNABERT-2-Finetune-1400'\n",
        "    checkpoint = DNABERT_2_checkpoint\n",
        "    print(checkpoint)\n",
        "\n",
        "    model_max_length = 636\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(checkpoint, model_max_length=model_max_length, trust_remote_code=True)\n",
        "    dna_bert_2 = AutoModel.from_pretrained(checkpoint,trust_remote_code=False) # trust_remote_code=True\n",
        "\n",
        "    # cuda\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Let's use, {device}!\")\n",
        "\n",
        "    dna_bert_2 = dna_bert_2.to(device)\n",
        "    dna_bert_2.eval()\n",
        "\n",
        "    # hyper-parameters\n",
        "    batch_size = 16\n",
        "\n",
        "    # dataset and dataloader\n",
        "    dataset = SeqenceDataset(dna_file)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=lambda x: collate_fn(x, tokenizer))\n",
        "\n",
        "    #\n",
        "    nesg_dnabert_scaler_file = f'{resource_dir}/nesg_dnabert_scaler.pickle'\n",
        "    with open(nesg_dnabert_scaler_file, 'rb') as w:\n",
        "        nesg_dnabert_scaler = pickle.load(w)\n",
        "\n",
        "    scaler = nesg_dnabert_scaler['TT Scaler']\n",
        "\n",
        "    # embedding\n",
        "    return dnabert_embedding(dna_bert_2, dataloader, scaler, dna_dnabert_embedding_pickle, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "d37f7925",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.543387Z",
          "start_time": "2024-06-18T13:46:11.539896Z"
        },
        "id": "d37f7925",
        "collapsed": true,
        "outputId": "84d3d595-7ceb-47fc-bc70-a5c856e1587e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "85399039d0bd483f9d9ea3522e4ccc05",
            "827e4a250a16481799e1687d550d35b0",
            "2fa5fe0495d3467ca08e5a7eb707215a",
            "cb7453a51cb943e982ad2b69d25d6e76",
            "6dcc2a8da9714a8a94fbf34ab1295137",
            "d5f13ac13c8646c296dfa24ac2c080e3",
            "6c8059e17788463ab4c0c27bdf5e14e6",
            "684775c7aa734c8aae70339e76001596",
            "51b1458c600d41c18107c96a9b14dd58",
            "3f010b62f08c4489b27338c16480c3bd",
            "019fec13ea8d4410b17e84439874b881"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DNABERT-2-Finetune-1400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at /content/DNABERT-2-Finetune-1400 and are newly initialized: ['bert.embeddings.position_embeddings.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's use, cuda!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.3.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85399039d0bd483f9d9ea3522e4ccc05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[146, 146, 146, 146, 146, 146, 146, 146]\n",
            "torch.Size([8, 146])\n",
            "8\n",
            "dict_keys(['scg_0', 'scg_1', 'scg_2', 'scg_3', 'scg_4', 'scg_5', 'scg_6', 'scg_7'])\n"
          ]
        }
      ],
      "source": [
        "if is_test:\n",
        "    dna_file = f'{res_dir}/{protein_name}_scg_dnas_test.csv'\n",
        "\n",
        "    # output\n",
        "    dna_dnabert_embedding_pickle = f'{res_dir}/{protein_name}_scg_dnas_dnabert_embedding_test.pickle'\n",
        "    # 这里出了问题\n",
        "    dna_dnabert_embedding = DNABERT_2_Embedding_Func(dna_file, dna_dnabert_embedding_pickle)\n",
        "\n",
        "    print(len(dna_dnabert_embedding))\n",
        "    print(dna_dnabert_embedding.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b997c803",
      "metadata": {
        "id": "b997c803"
      },
      "source": [
        "## Prediction of highly soluble expressed gene sequences using GELP models (SVM, LR, MLP, CNN-N-NF)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c31b909",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-17T07:44:27.634685Z",
          "start_time": "2024-06-17T07:44:27.632983Z"
        },
        "id": "2c31b909"
      },
      "source": [
        "### SVM, LR, MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a72c7639",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.548210Z",
          "start_time": "2024-06-18T13:46:11.544427Z"
        },
        "id": "a72c7639"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# 加载验证集数据\n",
        "def load_merge_embedding(dnabert_e, feature_e, print_info=True):\n",
        "    dnabert_embedding_data = None\n",
        "    with open(dnabert_e, 'rb') as file:\n",
        "        dnabert_embedding_data = pickle.load(file)\n",
        "\n",
        "    feature_embedding_data = None\n",
        "    with open(feature_e, 'rb') as file:\n",
        "        feature_embedding_data = pickle.load(file)\n",
        "\n",
        "    gene_name_info, seq_embedding_info, label_info = [], [], []\n",
        "\n",
        "    for gene_name in dnabert_embedding_data.keys():\n",
        "        data_de = dnabert_embedding_data[gene_name]\n",
        "        data_fe = feature_embedding_data[gene_name]\n",
        "\n",
        "        gene_name_info.append(gene_name)\n",
        "        seq_embedding_info.append(np.concatenate([data_de['embedding'], data_fe['embedding']]))\n",
        "        label_info.append(data_de['label'])\n",
        "\n",
        "    if print_info:\n",
        "        print(dnabert_e, feature_e)\n",
        "        print(len(gene_name_info), len(seq_embedding_info), len(label_info))\n",
        "        print(gene_name_info[:3], label_info[:3], len(\n",
        "            seq_embedding_info[0]), seq_embedding_info[0])\n",
        "\n",
        "    return gene_name_info, seq_embedding_info, label_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "253d64ba",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.553213Z",
          "start_time": "2024-06-18T13:46:11.549132Z"
        },
        "id": "253d64ba"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "def Sklearn_model(dnabert_2_dataset, dna_feature_dataset):\n",
        "    names, df_X, df_y = load_merge_embedding(dnabert_2_dataset, dna_feature_dataset)\n",
        "\n",
        "    best_model_file = f'{resource_dir}/sklearn_best_model.pickle'\n",
        "    with open(best_model_file, 'rb') as f:\n",
        "        sklearn_best_model = pickle.load(f)\n",
        "\n",
        "    res = {}\n",
        "    for key in sklearn_best_model.keys():\n",
        "        if 'Acc' in key:\n",
        "            continue\n",
        "\n",
        "        model = sklearn_best_model[key]\n",
        "        print(key)\n",
        "\n",
        "        y_ppba = model.predict_proba(df_X)\n",
        "        y_score = y_ppba[:, 1]\n",
        "\n",
        "\n",
        "        res_d = {}\n",
        "        for output, name in zip(y_score, names):\n",
        "            res_d[name] = output\n",
        "\n",
        "        res_d = sorted(res_d.items(), key=lambda x: x[1], reverse=True)\n",
        "#         print(res_d)\n",
        "\n",
        "        res_d_n = {}\n",
        "        for i, (k, v) in enumerate(res_d, start=1):\n",
        "            res_d_n[k] = [v, i]\n",
        "\n",
        "        res[key] = res_d_n\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e3cb2364",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.563299Z",
          "start_time": "2024-06-18T13:46:11.554263Z"
        },
        "scrolled": true,
        "id": "e3cb2364",
        "outputId": "53cc8c4d-bc56-4056-cffe-3129ecc05f5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scg-gelp-res/SSS_scg_dnas_dnabert_embedding_test.pickle scg-gelp-res/SSS_scg_dnas_feature_embedding_test.pickle\n",
            "8 8 8\n",
            "['scg_0', 'scg_1', 'scg_2'] [-1, -1, -1] 1792 [-0.68472907  1.04326984  0.99151609 ...  0.21629816  0.39465921\n",
            "  0.44847721]\n",
            "SVM\n",
            "LR\n",
            "MLP\n",
            "{'SVM': {'scg_0': [0.2826551466033763, 1], 'scg_1': [0.2826551466033763, 2], 'scg_2': [0.2826551466033763, 3], 'scg_3': [0.2826551466033763, 4], 'scg_4': [0.2826551466033763, 5], 'scg_5': [0.2826551466033763, 6], 'scg_6': [0.2826551466033763, 7], 'scg_7': [0.2826551466033763, 8]}, 'LR': {'scg_7': [3.126152067905611e-19, 1], 'scg_5': [2.941136860035249e-19, 2], 'scg_3': [2.7798732168905763e-19, 3], 'scg_2': [2.6555552101047187e-19, 4], 'scg_1': [2.4996730108552474e-19, 5], 'scg_4': [2.2605722362075303e-19, 6], 'scg_0': [2.160646752091724e-19, 7], 'scg_6': [1.8633364910750946e-19, 8]}, 'MLP': {'scg_7': [5.317437621240147e-07, 1], 'scg_1': [5.22575282264105e-07, 2], 'scg_5': [5.222087194033358e-07, 3], 'scg_2': [4.921431501856002e-07, 4], 'scg_6': [4.881982881052121e-07, 5], 'scg_3': [4.859747221215828e-07, 6], 'scg_0': [4.827959238906947e-07, 7], 'scg_4': [4.76038639007404e-07, 8]}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.3.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.3.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelBinarizer from version 1.3.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MLPClassifier from version 1.3.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "if is_test:\n",
        "    dna_feature_embedding_pickle = f'{res_dir}/{protein_name}_scg_dnas_feature_embedding_test.pickle'\n",
        "    dna_dnabert_embedding_pickle = f'{res_dir}/{protein_name}_scg_dnas_dnabert_embedding_test.pickle'\n",
        "\n",
        "    res = Sklearn_model(dna_dnabert_embedding_pickle, dna_feature_embedding_pickle)\n",
        "    print(res)\n",
        "    df = pd.DataFrame(res)\n",
        "    df.to_csv(f\"{res_dir}/res.csv\")\n",
        "#     raise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5a781ea",
      "metadata": {
        "id": "a5a781ea"
      },
      "source": [
        "### CNN-N-NF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "eedbc999",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.572592Z",
          "start_time": "2024-06-18T13:46:11.564264Z"
        },
        "id": "eedbc999"
      },
      "outputs": [],
      "source": [
        "nuclue_natural_number = {'AAA': 1, 'GAA': 2, 'GAT': 3, 'ATT': 4, 'AAT': 5, 'CTG': 6, 'TTT': 7, 'ATG': 8, 'TAT': 9, 'GCA': 10, 'CAG': 11, 'GGT': 12, 'GTT': 13, 'GAG': 14, 'AAC': 15, 'TTA': 16, 'GCT': 17, 'ATC': 18, 'GCC': 19, 'GGC': 20, 'GCG': 21, 'GAC': 22, 'AAG': 23, 'CTT': 24, 'ATA': 25, 'GTG': 26, 'CAA': 27, 'ACA': 28, 'ACC': 29, 'TCA': 30, 'TTC': 31, 'TGG': 32, 'GGA': 33, 'GTA': 34, 'TCT': 35, 'TTG': 36, 'ACT': 37, 'CGT': 38, 'AGC': 39, 'CAT': 40, 'AGT': 41, 'CGC': 42, 'TAC': 43, 'CCG': 44, 'GGG': 45, 'GTC': 46, 'ACG': 47, 'CCA': 48, 'CCT': 49, 'AGA': 50, 'CTC': 51, 'TCC': 52, 'CAC': 53, 'TCG': 54, 'CTA': 55, 'TGT': 56, 'CGG': 57, 'TGC': 58, 'CCC': 59, 'CGA': 60, 'AGG': 61, 'TAA': 62, 'TGA': 63, 'TAG': 64}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "1e47ffc2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.577393Z",
          "start_time": "2024-06-18T13:46:11.573552Z"
        },
        "code_folding": [],
        "id": "1e47ffc2"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import csv\n",
        "\n",
        "class CNNSequenceDataset(Dataset):\n",
        "    def __init__(self, data_file: str, feature_file: str):\n",
        "\n",
        "        super(CNNSequenceDataset, self).__init__()\n",
        "\n",
        "        # load data from the disk\n",
        "        with open(data_file, \"r\") as f:\n",
        "            data = list(csv.reader(f))[1:]\n",
        "\n",
        "        self.names = [d[0] for d in data]\n",
        "        self.texts = [d[1] for d in data]\n",
        "        self.labels = [int(d[2]) for d in data]\n",
        "\n",
        "        with open(feature_file, 'rb') as file:\n",
        "            self.feature_embedding_data = pickle.load(file)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.names[i], self.texts[i], self.labels[i], self.feature_embedding_data[self.names[i]]['embedding']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "2dbc311f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.583170Z",
          "start_time": "2024-06-18T13:46:11.578368Z"
        },
        "code_folding": [
          6
        ],
        "id": "2dbc311f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import pickle\n",
        "\n",
        "def encode(seq: str, encode_type):\n",
        "    if encode_type is None:\n",
        "        return seq\n",
        "\n",
        "    # 'number-id'\n",
        "    tokens =  [seq[i: i+3] for i in range(0, len(seq), 3)]\n",
        "    nuclue_natural_number_idx = [nuclue_natural_number.get(token, 0) for token in tokens]\n",
        "\n",
        "    if encode_type == 'One-hot':\n",
        "        # return len * 65\n",
        "        embedding = np.zeros([len(nuclue_natural_number_idx), len(nuclue_natural_number) + 1])\n",
        "\n",
        "        for idx, number_id in enumerate(nuclue_natural_number_idx):\n",
        "            embedding[idx][number_id] = 1\n",
        "    else:\n",
        "        # return list: 1 * len\n",
        "        embedding = nuclue_natural_number_idx\n",
        "\n",
        "    embedding = torch.tensor(embedding)\n",
        "\n",
        "    return embedding\n",
        "\n",
        "def cnn_collate_fn(batch_samples, encode_type=None):\n",
        "    assert encode_type in [None, 'natural-number', 'One-hot']\n",
        "\n",
        "    batch_names = []\n",
        "    batch_texts = []\n",
        "    batch_labels = []\n",
        "\n",
        "    fea_embedding = []\n",
        "\n",
        "    for sample in batch_samples:\n",
        "        batch_names.append(sample[0])\n",
        "\n",
        "        embedding = encode(sample[1], encode_type)\n",
        "\n",
        "        batch_texts.append(embedding)\n",
        "        batch_labels.append(sample[2])\n",
        "\n",
        "        fea_embedding.append(sample[3])\n",
        "\n",
        "    if encode_type is None:\n",
        "        X = batch_texts\n",
        "    else:\n",
        "        # 填充句子到相同长度\n",
        "        X = pad_sequence(batch_texts, batch_first=True, padding_value=0)\n",
        "\n",
        "    y = torch.tensor(batch_labels)\n",
        "\n",
        "    fea = torch.tensor(fea_embedding, dtype=torch.float32)\n",
        "\n",
        "    return X, y, fea, batch_names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "a08fb2c5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.593009Z",
          "start_time": "2024-06-18T13:46:11.584258Z"
        },
        "code_folding": [
          2,
          16,
          57
        ],
        "id": "a08fb2c5"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class CnnConfig:\n",
        "    def __init__(self, inc, outc, ks, pks):\n",
        "        # 输入数据高度，RGB 3\n",
        "        self.in_channel = inc\n",
        "\n",
        "        # 卷积核个数 16\n",
        "        self.out_channel = outc\n",
        "\n",
        "        # 卷积核大小 (3, 25)\n",
        "        self.kernel_size = ks\n",
        "\n",
        "        # 池化 (2, 2)\n",
        "        self.pool_kernel_size = pks\n",
        "\n",
        "class ModelConfig:\n",
        "    def __init__(self, cnn_channel: list, first_kernel_list: list, other_kernel_size: list, encode_type: str, is_add_feature=False):\n",
        "        self.encode_type = True if encode_type == 'natural-number' else False\n",
        "\n",
        "        self.is_add_feature = is_add_feature\n",
        "\n",
        "        # 嵌入参数: 输入 batch*seq_len*1 -> batch*seq_len*512\n",
        "        self.num_embeddings = 65\n",
        "        self.embedding_dim = cnn_channel[0]\n",
        "\n",
        "        # 经过变换：-> batch*64*seq_len，输入通道都是\n",
        "\n",
        "        # 拉链式 卷积参数\n",
        "        self.module_list = []\n",
        "\n",
        "#         first_kernel_list = [i for i in range(min_kernel, max_kernel)]\n",
        "        first_kernel_list = first_kernel_list\n",
        "        cnn_channel_list = cnn_channel\n",
        "\n",
        "        other_kernel_size = other_kernel_size\n",
        "\n",
        "        pool_kernel_size = 2\n",
        "\n",
        "        for _kernel in first_kernel_list:\n",
        "            line_cnn = []\n",
        "            all_kernel_size = [_kernel] + other_kernel_size\n",
        "            for idx in range(len(cnn_channel_list) - 1):\n",
        "                line_cnn.append(CnnConfig(cnn_channel_list[idx],\n",
        "                                          cnn_channel_list[idx + 1],\n",
        "                                          all_kernel_size[idx],\n",
        "                                          pool_kernel_size))\n",
        "            self.module_list.append(line_cnn)\n",
        "\n",
        "        # 全连接\n",
        "        self.dropout_rate = 0.1\n",
        "        self.in_features = cnn_channel_list[-1] * len(first_kernel_list)\n",
        "        if self.is_add_feature:\n",
        "            self.in_features += 1024\n",
        "\n",
        "        self.num_class = 2\n",
        "\n",
        "class KMersCNN(nn.Module):\n",
        "    # https://blog.csdn.net/sunny_xsc1994/article/details/82969867\n",
        "    def __init__(self, model_config: ModelConfig):\n",
        "        super(KMersCNN, self).__init__()\n",
        "\n",
        "        self.args = model_config\n",
        "\n",
        "        self.use_embedding = self.args.encode_type\n",
        "        self.is_add_feature = self.args.is_add_feature\n",
        "\n",
        "        # https://www.jianshu.com/p/63e7acc5e890\n",
        "        # 词嵌入: 词典大小为 25, 嵌入维度 64\n",
        "        if self.use_embedding:\n",
        "            self.embedding = nn.Embedding(num_embeddings=self.args.num_embeddings,\n",
        "                                          embedding_dim=self.args.embedding_dim)\n",
        "\n",
        "        # 卷积\n",
        "        self.convs = nn.ModuleList()\n",
        "        for sequential in self.args.module_list:\n",
        "            layers = nn.Sequential()\n",
        "            for cnn in sequential:\n",
        "                # Conv1d 输入的形状通常为 (batch_size, input_channels, sequence_length)\n",
        "                layers.append(nn.Conv1d(in_channels=cnn.in_channel,\n",
        "                              out_channels=cnn.out_channel,\n",
        "                              kernel_size=cnn.kernel_size))\n",
        "\n",
        "                layers.append(nn.BatchNorm1d(cnn.out_channel))\n",
        "                layers.append(nn.ReLU())\n",
        "                layers.append(nn.Dropout1d(p=self.args.dropout_rate))\n",
        "                layers.append(nn.MaxPool1d(kernel_size=cnn.pool_kernel_size))\n",
        "\n",
        "            self.convs.append(layers)\n",
        "\n",
        "        if self.is_add_feature:\n",
        "            self.bn1, self.bn2 = nn.BatchNorm1d(self.args.in_features - 1024), nn.BatchNorm1d(self.args.in_features)\n",
        "        else:\n",
        "            self.bn1, self.bn2 = nn.BatchNorm1d(self.args.in_features), None\n",
        "\n",
        "        # 全连接\n",
        "        self.fc = nn.Linear(in_features=self.args.in_features,\n",
        "                            out_features=self.args.num_class)\n",
        "\n",
        "        # self.apply() 是 nn.Module 类的一个方法，它接受一个函数作为参数，并将该函数应用到模型的每个子模块\n",
        "        self.apply(self.initialize_weights)\n",
        "\n",
        "    def forward(self, x, batch_fea):\n",
        "        x = x.to(torch.float32)\n",
        "#         print(x.size())\n",
        "\n",
        "        if self.use_embedding:\n",
        "            x = x.to(torch.long)\n",
        "            x = self.embedding(x)\n",
        "#             print(x.size())\n",
        "\n",
        "        x = x.permute(0, 2, 1)\n",
        "#         print(x.size())\n",
        "\n",
        "        outs = []\n",
        "        for conv in self.convs:\n",
        "#             print(x.dtype, conv)\n",
        "            out = conv(x)\n",
        "#             print(out.size(), out.size(-1))\n",
        "\n",
        "            # 手动获取最后一维大小，并做 MaxPool\n",
        "            max_pool = nn.MaxPool1d(out.size(-1))\n",
        "            out = max_pool(out)\n",
        "#             print(out.size())\n",
        "\n",
        "            outs.append(out)\n",
        "\n",
        "#         out = [conv(x) for conv in self.convs]\n",
        "#         for item in out:\n",
        "#             print(item.size())\n",
        "\n",
        "        out = torch.cat(outs, dim=1)\n",
        "#         print(out.size())\n",
        "\n",
        "        out = out.view(-1, out.size(1))\n",
        "#         print(out.size())\n",
        "\n",
        "        out = self.bn1(out)\n",
        "\n",
        "        if self.is_add_feature:\n",
        "            out = torch.cat([out, batch_fea], dim=1)\n",
        "\n",
        "            out = self.bn2(out)\n",
        "\n",
        "#         raise\n",
        "        out = F.dropout(input=out, p=self.args.dropout_rate)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def initialize_weights(self, m):\n",
        "        if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
        "            nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "7eb0b60b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.598236Z",
          "start_time": "2024-06-18T13:46:11.594137Z"
        },
        "id": "7eb0b60b"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
        "\n",
        "def predict(model, dataloader, device, use_tqdm=False):\n",
        "    if use_tqdm:\n",
        "        progress_bar = tqdm(range(len(dataloader)))\n",
        "\n",
        "    # 计算指标\n",
        "    model_output = []\n",
        "    batch_names = []\n",
        "\n",
        "    model.eval()\n",
        "    for batch_X, batch_y, batch_fea, batch_name in dataloader:\n",
        "        batch_names += batch_name\n",
        "\n",
        "        batch_X = batch_X.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "        batch_fea = batch_fea.to(device)\n",
        "\n",
        "        pred = model(batch_X, batch_fea)\n",
        "\n",
        "        model_output.append(F.softmax(pred).cpu().detach().numpy())\n",
        "\n",
        "        if use_tqdm:\n",
        "            progress_bar.update(1)\n",
        "\n",
        "    # 模型的输出概率值\n",
        "    model_output = np.concatenate(model_output, axis =0)\n",
        "\n",
        "    res_d = {}\n",
        "    for output, name in zip(model_output[:, 1], batch_names):\n",
        "        res_d[name] = output\n",
        "\n",
        "    res_d = sorted(res_d.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    res_d_n = {}\n",
        "    for i, (k, v) in enumerate(res_d, start=1):\n",
        "        res_d_n[k] = [v, i]\n",
        "\n",
        "    return res_d_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "8d01cb66",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.603647Z",
          "start_time": "2024-06-18T13:46:11.599241Z"
        },
        "id": "8d01cb66"
      },
      "outputs": [],
      "source": [
        "# main\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "def CNN_NNF(data_csv, dna_feature_embedding):\n",
        "    # 1 file\n",
        "\n",
        "    # 2 data dataset dataloader\n",
        "    batch_size = 16\n",
        "    encode_type = 'natural-number'\n",
        "    # encode_type = 'One-hot'\n",
        "\n",
        "    val_dataset = CNNSequenceDataset(data_csv, dna_feature_embedding)\n",
        "\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: cnn_collate_fn(x, encode_type))\n",
        "\n",
        "    # 3 model 1\n",
        "    min_kernel = 1\n",
        "    max_kernel = 16\n",
        "    cnn_channel = [512, 512, 512]\n",
        "    first_kernel_list = [i for i in range(min_kernel, max_kernel)]\n",
        "    other_kernel_size = [2]\n",
        "\n",
        "    is_add_fea = False\n",
        "\n",
        "    def get_list_info(_list):\n",
        "        _str = ''\n",
        "        for _item in _list:\n",
        "            _str = _str + '-' + str(_item)\n",
        "        return _str[1:]\n",
        "\n",
        "    tag = f'nesg-cnn-{encode_type}-{get_list_info(cnn_channel)}-{min_kernel}-{max_kernel}-{get_list_info(other_kernel_size)}-{is_add_fea}'\n",
        "\n",
        "    checkpoint_path = f'{resource_dir}/{tag}.pt'\n",
        "    print(checkpoint_path)\n",
        "\n",
        "    model_config = ModelConfig(cnn_channel, first_kernel_list, other_kernel_size, encode_type, is_add_feature=is_add_fea)\n",
        "    model = KMersCNN(model_config)\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    curr_epoch = checkpoint['epoch'] + 1\n",
        "    bast_acc = checkpoint['acc']\n",
        "\n",
        "    print(f'resume: epoch {curr_epoch}, acc {bast_acc}')\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    pre_res = predict(model, val_dataloader, device)\n",
        "\n",
        "    return {\n",
        "        'CNN-NNF': pre_res\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "468e9e9f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.607927Z",
          "start_time": "2024-06-18T13:46:11.604765Z"
        },
        "code_folding": [],
        "id": "468e9e9f",
        "outputId": "8d3af7c9-e8a2-45f7-bb3c-445ef39d69c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SCG-GELP/nesg-cnn-natural-number-512-512-512-1-16-2-False.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-79882aaeb9f8>:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resume: epoch 60, acc 0.7333333333333333\n",
            "{'CNN-NNF': {'scg_5': [0.93996376, 1], 'scg_0': [0.9365017, 2], 'scg_7': [0.9357137, 3], 'scg_1': [0.93006915, 4], 'scg_4': [0.87643385, 5], 'scg_6': [0.83215314, 6], 'scg_3': [0.8289164, 7], 'scg_2': [0.81719404, 8]}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-b6cd469ccbbe>:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  model_output.append(F.softmax(pred).cpu().detach().numpy())\n"
          ]
        }
      ],
      "source": [
        "if is_test:\n",
        "    dna_file = f'{res_dir}/{protein_name}_scg_dnas_test.csv'\n",
        "    dna_feature_embedding_pickle = f'{res_dir}/{protein_name}_scg_dnas_feature_embedding_test.pickle'\n",
        "\n",
        "    res = CNN_NNF(dna_file, dna_feature_embedding_pickle)\n",
        "    print(res)\n",
        "\n",
        "    # raise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e8dbdba",
      "metadata": {
        "id": "3e8dbdba"
      },
      "source": [
        "## Screening results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ed6fb78",
      "metadata": {
        "id": "0ed6fb78"
      },
      "source": [
        "### Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "0ce7e53a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:46:11.613587Z",
          "start_time": "2024-06-18T13:46:11.608968Z"
        },
        "code_folding": [],
        "id": "0ce7e53a"
      },
      "outputs": [],
      "source": [
        "def run(predict_data_dir, protein_name, protein_seq, dna_seq_now):\n",
        "    # files\n",
        "    print(f'Start: {protein_name}')\n",
        "\n",
        "    # 保存原始的 DNA 序列， 用于特征提取\n",
        "    dna_file = f'{predict_data_dir}/{protein_name}_scg_dnas.csv'\n",
        "\n",
        "    # DNABERT-2 提取特征 结果文件\n",
        "    dna_dnabert_embedding_pickle = f'{predict_data_dir}/{protein_name}_scg_dnas_dnabert_embedding.pickle'\n",
        "\n",
        "    # 特征工程编码 结果文件\n",
        "    dna_feature_embedding_pickle = f'{predict_data_dir}/{protein_name}_scg_dna_feature_embedding.pickle'\n",
        "\n",
        "    if exec_func['Exec SCG Model']:\n",
        "#         beam_batch_sizes, beam_widths = [1, 2, 4, 8, 16, 32], [2, 2, 3, 4, 5, 5]\n",
        "#         beam_sizes = [val * 20 for val in beam_batch_sizes]\n",
        "\n",
        "        dnas = SCG_Transformer_predict(protein_seq, beam_batch_sizes, beam_widths, beam_sizes)\n",
        "\n",
        "        # 用于 DNABERT-2 提取特征, 预测及原始的 DNA 序列\n",
        "        with open(dna_file, 'w', encoding='utf-8') as w:\n",
        "            w.write('name,label,nucle-seq\\n')\n",
        "            for i, dna in enumerate(dnas):\n",
        "                w.write(f'{protein_name}_scg_{i},{dna},-1\\n')\n",
        "\n",
        "            # 保存已有的\n",
        "            for k in dna_seq_now:\n",
        "                w.write(f'{k},{dna_seq_now[k]},-1\\n')\n",
        "\n",
        "    print()\n",
        "    if exec_func['Exec DNA Feature']:\n",
        "        Fearture_embedding(dna_file, dna_feature_embedding_pickle)\n",
        "\n",
        "    print()\n",
        "    if exec_func['Exec DNABERT-2 Model']:\n",
        "        # DNABERT-2 提取特征\n",
        "        dna_dnabert_embedding = DNABERT_2_Embedding_Func(dna_file, dna_dnabert_embedding_pickle)\n",
        "\n",
        "        print(len(dna_dnabert_embedding))\n",
        "        print(list(dna_dnabert_embedding.keys())[-10:])\n",
        "\n",
        "    print()\n",
        "    if exec_func['Exec Sklearn model']:\n",
        "        sk_res = Sklearn_model(dna_dnabert_embedding_pickle, dna_feature_embedding_pickle)\n",
        "#         print(res)\n",
        "\n",
        "    print()\n",
        "    if exec_func['Exec CNN-N-NF model']:\n",
        "        cnn_res = CNN_NNF(dna_file, dna_feature_embedding_pickle)\n",
        "#         print(res2)\n",
        "\n",
        "    sk_res.update(cnn_res)\n",
        "\n",
        "    # save to pickle\n",
        "    predict_res_pickle = f'{predict_data_dir}/{protein_name}_predict_res.pickle'\n",
        "    with open(predict_res_pickle, 'wb') as w:\n",
        "        pickle.dump(sk_res, w)\n",
        "\n",
        "    print(f'Info: {protein_name} predict res save to {predict_res_pickle}')\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "711603d4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:49:32.566975Z",
          "start_time": "2024-06-18T13:46:11.614690Z"
        },
        "id": "711603d4",
        "outputId": "c224fdb8-f819-48a0-b224-aef440746d1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571,
          "referenced_widgets": [
            "14d178a0f26d4afda1c24868371fd2cf",
            "9994eee5df3845ca843815bfede53bc7",
            "1bc839847a314a72a73ee7a3cdf0897d",
            "60f96509eac24115a8a45b8f2430a1d6",
            "3e7934aaaad44dfaa62a9a374103b011",
            "46d2bf05dc3c4cdd8e6c076b056fab64",
            "3dd78e447f8e49eabab47948c6d678f4",
            "e45d274c33d842499e292e661716e63a",
            "dc3106722cf14cbb9c478a4337e9135f",
            "12a930e13d274595b9e2bd4c5f286ce1",
            "04d0be906a0a4cb690f323d8f3416029"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start: SSS\n",
            "modle: /content/SCG-GELP/tf_0.0001_512_8_3_3_512_0.1_1024_6.pt\n",
            "device: cuda\n",
            "resume train: epoch 47, loss 0.9707116135501553\n",
            "12707396\n",
            "None\n",
            "beam search args: [4] [5] [8]\n",
            "args: 4 5 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-a35e589a1a82>:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/239 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14d178a0f26d4afda1c24868371fd2cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCG return dna num: 8\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "list indices must be integers or slices, not str",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-ef2ea0a9e2df>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotein_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotein_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdnas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-ef9c9f745fd8>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(predict_data_dir, protein_name, protein_seq, dna_seq_now)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# 保存已有的\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdna_seq_now\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{k},{dna_seq_now[k]},-1\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ],
      "source": [
        "run(res_dir, protein_name, protein_seq, dnas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "a2f0679d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:49:32.570937Z",
          "start_time": "2024-06-18T13:49:32.568335Z"
        },
        "id": "a2f0679d"
      },
      "outputs": [],
      "source": [
        "### Screening results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "81fe273e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-18T13:49:32.586366Z",
          "start_time": "2024-06-18T13:49:32.572093Z"
        },
        "id": "81fe273e",
        "outputId": "ce503a3a-bde6-4df5-dd66-bc3be7c97d99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'scg-gelp-res/SSS_predict_res.pickle'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-5722a97b2eed>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredict_res_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{res_dir}/{protein_name}_predict_res.pickle'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_res_pickle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'scg-gelp-res/SSS_predict_res.pickle'"
          ]
        }
      ],
      "source": [
        "predict_res_pickle = f'{res_dir}/{protein_name}_predict_res.pickle'\n",
        "with open(predict_res_pickle, 'rb') as r:\n",
        "    res = pickle.load(r)\n",
        "\n",
        "model_names = list(res.keys())\n",
        "\n",
        "# 取第二个模型的 排名\n",
        "seq_names = list(res[model_names[model_id]].keys())\n",
        "\n",
        "print(model_names, seq_names[:3], res[model_names[model_id]][seq_names[0]])\n",
        "\n",
        "# save all data to csv\n",
        "gs_acc, gs_rank = 0, 0\n",
        "res_file = f'{res_dir}/{protein_name}_predict_res.csv'\n",
        "with open(res_file, 'w', encoding='utf-8') as w:\n",
        "    head_names_str = ''\n",
        "    for model_name in model_names:\n",
        "        head_names_str += f'{model_name} Acc,{model_name} Rank,'\n",
        "\n",
        "    w.write(f'name,{head_names_str[:-1]},Total Acc,Total Rank,info\\n')\n",
        "\n",
        "    for seq_name in seq_names:\n",
        "        acc_rank_str = ''\n",
        "        acc_tol, rank_tol = 0, 0\n",
        "\n",
        "        for model_name in model_names:\n",
        "            item = res[model_name][seq_name]\n",
        "            acc_rank_str += f'{item[0]},{item[1]},'\n",
        "\n",
        "            acc_tol += item[0]\n",
        "            rank_tol += item[1]\n",
        "\n",
        "        w.write(f'{seq_name},{acc_rank_str[:-1]},{acc_tol/len(model_names)},{rank_tol/len(model_names)}\\n')\n",
        "\n",
        "print(f'Info: {protein_name} predict res save to {res_file}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JYjzRJHhrXOP"
      },
      "id": "JYjzRJHhrXOP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18f6e7693df54a38a068922f5980b5b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4362077d4f64df5ba781f1f47edd4e1",
              "IPY_MODEL_7ed63e680105458db59b6b37eb91c5b6",
              "IPY_MODEL_ec99b2f3c7ea4d19873076be93fbc095"
            ],
            "layout": "IPY_MODEL_131e7361c76c4b02bc71add3f1861e31"
          }
        },
        "b4362077d4f64df5ba781f1f47edd4e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05cff9428f8f4d4d9799b257b9e1cac9",
            "placeholder": "​",
            "style": "IPY_MODEL_bd71c110477342139ae439b46527b140",
            "value": "100%"
          }
        },
        "7ed63e680105458db59b6b37eb91c5b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_368911d2e48542e0a2504c4f6edc4245",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_637e744961a8488886c3e2410b868721",
            "value": 238
          }
        },
        "ec99b2f3c7ea4d19873076be93fbc095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b4e60a9e1cb4f19aa516b1628e5fabe",
            "placeholder": "​",
            "style": "IPY_MODEL_c3e70e8c739a4c32a8127bc864a26226",
            "value": " 238/239 [00:04&lt;00:00, 64.09it/s]"
          }
        },
        "131e7361c76c4b02bc71add3f1861e31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05cff9428f8f4d4d9799b257b9e1cac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd71c110477342139ae439b46527b140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "368911d2e48542e0a2504c4f6edc4245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "637e744961a8488886c3e2410b868721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b4e60a9e1cb4f19aa516b1628e5fabe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e70e8c739a4c32a8127bc864a26226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e4dc56cab5249aca4f45695c07da743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39e15caf31e642dd85c4f6431850d100",
              "IPY_MODEL_f10a959c3bbc4e929594e62e274496a3",
              "IPY_MODEL_09289f15d4a1425f9d7c34d05c3bc07a"
            ],
            "layout": "IPY_MODEL_76c5e4202d514d9e9dbd04206117a072"
          }
        },
        "39e15caf31e642dd85c4f6431850d100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75f0a457195c41bea5de9c70db00cc69",
            "placeholder": "​",
            "style": "IPY_MODEL_4181084e467f488397ef7cf0c7b7ff73",
            "value": "100%"
          }
        },
        "f10a959c3bbc4e929594e62e274496a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d5b69e94ebb4bfeb4ed386580604f6d",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b140b08930c3490d88e8add8af016516",
            "value": 8
          }
        },
        "09289f15d4a1425f9d7c34d05c3bc07a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c14622011fe842c5bd138e4b99bf7bd8",
            "placeholder": "​",
            "style": "IPY_MODEL_1e53510b76b54fd6b7719179180ea6a7",
            "value": " 8/8 [00:01&lt;00:00,  6.77it/s]"
          }
        },
        "76c5e4202d514d9e9dbd04206117a072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75f0a457195c41bea5de9c70db00cc69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4181084e467f488397ef7cf0c7b7ff73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d5b69e94ebb4bfeb4ed386580604f6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b140b08930c3490d88e8add8af016516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c14622011fe842c5bd138e4b99bf7bd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e53510b76b54fd6b7719179180ea6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85399039d0bd483f9d9ea3522e4ccc05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_827e4a250a16481799e1687d550d35b0",
              "IPY_MODEL_2fa5fe0495d3467ca08e5a7eb707215a",
              "IPY_MODEL_cb7453a51cb943e982ad2b69d25d6e76"
            ],
            "layout": "IPY_MODEL_6dcc2a8da9714a8a94fbf34ab1295137"
          }
        },
        "827e4a250a16481799e1687d550d35b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5f13ac13c8646c296dfa24ac2c080e3",
            "placeholder": "​",
            "style": "IPY_MODEL_6c8059e17788463ab4c0c27bdf5e14e6",
            "value": "100%"
          }
        },
        "2fa5fe0495d3467ca08e5a7eb707215a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_684775c7aa734c8aae70339e76001596",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51b1458c600d41c18107c96a9b14dd58",
            "value": 1
          }
        },
        "cb7453a51cb943e982ad2b69d25d6e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f010b62f08c4489b27338c16480c3bd",
            "placeholder": "​",
            "style": "IPY_MODEL_019fec13ea8d4410b17e84439874b881",
            "value": " 1/1 [00:00&lt;00:00,  4.22it/s]"
          }
        },
        "6dcc2a8da9714a8a94fbf34ab1295137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5f13ac13c8646c296dfa24ac2c080e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c8059e17788463ab4c0c27bdf5e14e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "684775c7aa734c8aae70339e76001596": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b1458c600d41c18107c96a9b14dd58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f010b62f08c4489b27338c16480c3bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "019fec13ea8d4410b17e84439874b881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14d178a0f26d4afda1c24868371fd2cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9994eee5df3845ca843815bfede53bc7",
              "IPY_MODEL_1bc839847a314a72a73ee7a3cdf0897d",
              "IPY_MODEL_60f96509eac24115a8a45b8f2430a1d6"
            ],
            "layout": "IPY_MODEL_3e7934aaaad44dfaa62a9a374103b011"
          }
        },
        "9994eee5df3845ca843815bfede53bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46d2bf05dc3c4cdd8e6c076b056fab64",
            "placeholder": "​",
            "style": "IPY_MODEL_3dd78e447f8e49eabab47948c6d678f4",
            "value": "100%"
          }
        },
        "1bc839847a314a72a73ee7a3cdf0897d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e45d274c33d842499e292e661716e63a",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc3106722cf14cbb9c478a4337e9135f",
            "value": 238
          }
        },
        "60f96509eac24115a8a45b8f2430a1d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12a930e13d274595b9e2bd4c5f286ce1",
            "placeholder": "​",
            "style": "IPY_MODEL_04d0be906a0a4cb690f323d8f3416029",
            "value": " 238/239 [00:03&lt;00:00, 55.32it/s]"
          }
        },
        "3e7934aaaad44dfaa62a9a374103b011": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46d2bf05dc3c4cdd8e6c076b056fab64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dd78e447f8e49eabab47948c6d678f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e45d274c33d842499e292e661716e63a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc3106722cf14cbb9c478a4337e9135f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12a930e13d274595b9e2bd4c5f286ce1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d0be906a0a4cb690f323d8f3416029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}